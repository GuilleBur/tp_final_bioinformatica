{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11-SmilesTokenizer.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WVfDx-LP9Bpp"},"source":["## Material de Referencia\n","- SmileTokenizer https://deepchem.readthedocs.io/en/2.4.0/api_reference/tokenizers.html\n","- Transformer model to extract embedding and use it as input to another classifier. https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n","\n","- Fine-tuning a pretrained model https://huggingface.co/transformers/training.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hRzQ6-dqopEk","executionInfo":{"status":"ok","timestamp":1629379573227,"user_tz":180,"elapsed":104215,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"3acf8024-4248-4afc-a5b6-d56860b62300"},"source":["%load_ext autoreload\n","%autoreload 2\n","import os.path\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","from tensorflow.keras import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, Dropout, Activation, BatchNormalization, Conv1D, MaxPool1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Flatten, Input, Concatenate\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras import backend as K\n","import tensorflow as tf\n","from tensorflow.keras import layers as L\n","\n","path = ''\n","if not os.path.isfile('001_Data_retrieve.ipynb'):\n","    !pip install -U -q PyDrive\n","    from pydrive.auth import GoogleAuth\n","    from pydrive.drive import GoogleDrive\n","    from google.colab import auth\n","    from oauth2client.client import GoogleCredentials\n","\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    path = '/content/drive/MyDrive/TRABAJO/Data Science/ITBA-DeepLearning/Notebooks/TP-FINAL/bioinformatics_final_project/'\n","    !pip install rdkit-pypi\n","    !pip install git+https://github.com/EBjerrum/molvecgen\n","    !pip install transformers\n","    !pip install deepchem\n","\n","    auth.authenticate_user()\n","    gauth = GoogleAuth()\n","    gauth.credentials = GoogleCredentials.get_application_default()\n","    drive = GoogleDrive(gauth)\n","    downloaded = drive.CreateFile({'id':'10fMCM9wnmjlyGwiyNzpfPROExiq8ukKk'})\n","    downloaded.GetContentFile('dataaug.py')\n","    downloaded = drive.CreateFile({'id':'1jPB1HDpGN5zFRuhqN6b9RLMuuUQy0UoB'})\n","    downloaded.GetContentFile('datagen.py')\n","    downloaded = drive.CreateFile({'id':'12FgtzBClWOeK6Kl3lEEV2YaTcXclHRzV'})\n","    downloaded.GetContentFile('smiles_tokenizer.py')\n","\n","from datagen import DataGenerator\n","    "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2021.3.4-cp37-cp37m-manylinux2014_x86_64.whl (18.6 MB)\n","\u001b[K     |████████████████████████████████| 18.6 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n","Installing collected packages: rdkit-pypi\n","Successfully installed rdkit-pypi-2021.3.4\n","Collecting git+https://github.com/EBjerrum/molvecgen\n","  Cloning https://github.com/EBjerrum/molvecgen to /tmp/pip-req-build-m22p810u\n","  Running command git clone -q https://github.com/EBjerrum/molvecgen /tmp/pip-req-build-m22p810u\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from molvecgen==0.1) (1.19.5)\n","Building wheels for collected packages: molvecgen\n","  Building wheel for molvecgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for molvecgen: filename=molvecgen-0.1-py3-none-any.whl size=11386 sha256=58187f5e93eb643d50d0a3546489e88c60d19eb95fb34a6ff11800395c45c364\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-l_zt86su/wheels/fe/f3/f6/b9c3409ce28e561f23bdc36bb487a3c9f181359e3ee4d22717\n","Successfully built molvecgen\n","Installing collected packages: molvecgen\n","Successfully installed molvecgen-0.1\n","Collecting transformers\n","  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 30.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 63.3 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 54.5 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting deepchem\n","  Downloading deepchem-2.5.0-py3-none-any.whl (552 kB)\n","\u001b[?25l\r\u001b[K     |▋                               | 10 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 552 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n","Installing collected packages: deepchem\n","Successfully installed deepchem-2.5.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mnDcqv1tZF-_"},"source":["## Carga de Datos"]},{"cell_type":"code","metadata":{"id":"eU9WYrEA1Xxg","executionInfo":{"status":"ok","timestamp":1629379579518,"user_tz":180,"elapsed":2776,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}}},"source":["df = pd.read_csv(path+'data/acetylcholinesterase_02_bioactivity_data_preprocessed.csv')\n","max_len_idx = df['canonical_smiles'].apply(len).argmax()\n","min_len_idx = df['canonical_smiles'].apply(len).argmin()\n","max_sequence_len = len(df['canonical_smiles'].iloc[max_len_idx]) + 20\n","\n","X = df['canonical_smiles'].values\n","y = df['pIC50'].values"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HraKnxgZF_E"},"source":["## Split de Datos"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YniLNKBgZF_G","executionInfo":{"status":"ok","timestamp":1629379583299,"user_tz":180,"elapsed":462,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"9e16ff73-c0d4-455a-cfca-7f0b51cfcfa1"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","if os.path.isfile('001_Data_retrieve.ipynb'):\n","  vocab_path = '/notebooks/TP-FINAL/bioinformatics_final_project/data'\n","else:\n","  vocab_path = path+'data'\n","\n","dgen_train = DataGenerator(X_train, y_train, seq_length=max_sequence_len, batch_size=128, data_augmentation=True, smilesTokenizer=True, vocab_path=vocab_path )\n","dgen_test = DataGenerator(X_test, y_test, seq_length=max_sequence_len, batch_size=128, data_augmentation=False, smilesTokenizer=True, vocab_path=vocab_path)\n","token = dgen_train.get_token()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n","Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n","Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n","Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ow89G461ZF_M"},"source":["## MODELO TextCNN"]},{"cell_type":"code","metadata":{"id":"JRIDXzrNZF_P"},"source":["# Implementar modelo de TextCNN similar a la deepchem\n","def text_cnn_1d(sequence_length, vocab_size, embedding_size, filter_sizes, num_filters):\n","    # Recordar que estamos en la funcional model API y hay que entender que conectar con que.\n","    input_x = Input(shape=(sequence_length,), name='input_x')\n","                          # cant caracteres unicos, #long vect Emb,  #max vocabulario     \n","    embedding_layer = Embedding(vocab_size+1, embedding_size, input_length=sequence_length  )(input_x)\n","    pooled_outputs = []\n","    for filter_size in filter_sizes:\n","        conv1D = Conv1D( num_filters, filter_size, padding='valid')(embedding_layer) #sin activacion !!\n","        max_p = GlobalMaxPooling1D()(conv1D)\n","        pooled_outputs.append(max_p)\n","        \n","    h_pool = Concatenate(axis=1)(pooled_outputs)\n","    ##h_pool = Flatten()(h_pool)  #Flatten porque tengo MaxPool1D en vez de GlobalMaxPooling1D?\n","    h_pool = Dropout(0.1)(h_pool)\n","    dense = Dense(200, activation='relu')(h_pool)\n","    \n","    #dense = Dense(50, activation='relu')(dense)\n","    dense = Dense(1)(dense) # Salida\n","    model = Model(input_x, dense)\n","    return model\n","\n","def R2(y_true, y_pred):\n","    SS_res =  K.sum(K.square( y_true-y_pred ))\n","    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n","    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n","\n","#Callbacks\n","earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2)\n","mcp = ModelCheckpoint(path+'/models/best_model', save_best_only=True, save_format=\"h5\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9skPi72ZF_S"},"source":["FILTER_SIZES = (3, 4, 5)\n","NUM_FILTERS = 128\n","vocab_size = token.vocab_size#len(smiles_dict)+1\n","embeddings_size = 128 # 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRasv6kVZF_U","executionInfo":{"status":"ok","timestamp":1628857184938,"user_tz":180,"elapsed":268,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"3e71a7e1-1338-4b7c-e7a1-dcde022b32ec"},"source":["model = text_cnn_1d(max_sequence_len, vocab_size, embeddings_size, FILTER_SIZES, NUM_FILTERS)\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[R2])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_x (InputLayer)            [(None, 227)]        0                                            \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 227, 128)     75776       input_x[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_9 (Conv1D)               (None, 225, 128)     49280       embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_10 (Conv1D)              (None, 224, 128)     65664       embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","conv1d_11 (Conv1D)              (None, 223, 128)     82048       embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","global_max_pooling1d_9 (GlobalM (None, 128)          0           conv1d_9[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_10 (Global (None, 128)          0           conv1d_10[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_11 (Global (None, 128)          0           conv1d_11[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 384)          0           global_max_pooling1d_9[0][0]     \n","                                                                 global_max_pooling1d_10[0][0]    \n","                                                                 global_max_pooling1d_11[0][0]    \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 384)          0           concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 200)          77000       dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1)            201         dense_6[0][0]                    \n","==================================================================================================\n","Total params: 349,969\n","Trainable params: 349,969\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KluPFQDAZF_V"},"source":["model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=[R2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxAbYXgBZF_X","outputId":"93bebda3-d5d9-473c-e51f-0fc4cfa8bd7b"},"source":["history = model.fit(dgen_train, epochs=2000, validation_data=dgen_test, callbacks=[earlystop])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/datagen.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  X_token = np.array([self.token.encode(smile) for smile in smilesBatch])\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/2000\n","32/32 [==============================] - 45s 1s/step - loss: 30.9195 - R2: -10.0988 - val_loss: 24.1586 - val_R2: -7.3696\n","Epoch 2/2000\n","32/32 [==============================] - 45s 1s/step - loss: 16.6795 - R2: -4.9873 - val_loss: 8.7439 - val_R2: -2.0293\n","Epoch 3/2000\n","32/32 [==============================] - 45s 1s/step - loss: 4.4395 - R2: -0.5936 - val_loss: 2.6648 - val_R2: 0.0768\n","Epoch 4/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.5884 - R2: 0.0709 - val_loss: 2.6163 - val_R2: 0.0936\n","Epoch 5/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.5229 - R2: 0.0944 - val_loss: 2.5663 - val_R2: 0.1109\n","Epoch 6/2000\n","32/32 [==============================] - 46s 1s/step - loss: 2.4838 - R2: 0.1084 - val_loss: 2.5196 - val_R2: 0.1271\n","Epoch 7/2000\n","32/32 [==============================] - 46s 1s/step - loss: 2.4464 - R2: 0.1218 - val_loss: 2.4716 - val_R2: 0.1437\n","Epoch 8/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.4091 - R2: 0.1352 - val_loss: 2.4247 - val_R2: 0.1600\n","Epoch 9/2000\n","32/32 [==============================] - 44s 1s/step - loss: 2.3711 - R2: 0.1489 - val_loss: 2.3799 - val_R2: 0.1755\n","Epoch 10/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.3348 - R2: 0.1619 - val_loss: 2.3362 - val_R2: 0.1906\n","Epoch 11/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.2988 - R2: 0.1748 - val_loss: 2.2936 - val_R2: 0.2054\n","Epoch 12/2000\n","32/32 [==============================] - 44s 1s/step - loss: 2.2628 - R2: 0.1878 - val_loss: 2.2515 - val_R2: 0.2200\n","Epoch 13/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.2293 - R2: 0.1998 - val_loss: 2.2107 - val_R2: 0.2341\n","Epoch 14/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.1911 - R2: 0.2135 - val_loss: 2.1713 - val_R2: 0.2478\n","Epoch 15/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.1551 - R2: 0.2264 - val_loss: 2.1325 - val_R2: 0.2612\n","Epoch 16/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.1210 - R2: 0.2386 - val_loss: 2.0953 - val_R2: 0.2741\n","Epoch 17/2000\n","32/32 [==============================] - 43s 1s/step - loss: 2.0873 - R2: 0.2507 - val_loss: 2.0601 - val_R2: 0.2863\n","Epoch 18/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.0533 - R2: 0.2629 - val_loss: 2.0272 - val_R2: 0.2977\n","Epoch 19/2000\n","32/32 [==============================] - 45s 1s/step - loss: 2.0178 - R2: 0.2757 - val_loss: 1.9967 - val_R2: 0.3083\n","Epoch 20/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.9809 - R2: 0.2890 - val_loss: 1.9681 - val_R2: 0.3182\n","Epoch 21/2000\n","32/32 [==============================] - 46s 1s/step - loss: 1.9496 - R2: 0.3002 - val_loss: 1.9413 - val_R2: 0.3274\n","Epoch 22/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.9224 - R2: 0.3100 - val_loss: 1.9147 - val_R2: 0.3367\n","Epoch 23/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.8906 - R2: 0.3214 - val_loss: 1.8891 - val_R2: 0.3455\n","Epoch 24/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.8592 - R2: 0.3326 - val_loss: 1.8641 - val_R2: 0.3542\n","Epoch 25/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.8339 - R2: 0.3417 - val_loss: 1.8395 - val_R2: 0.3627\n","Epoch 26/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.8082 - R2: 0.3509 - val_loss: 1.8151 - val_R2: 0.3712\n","Epoch 27/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.7810 - R2: 0.3607 - val_loss: 1.7896 - val_R2: 0.3800\n","Epoch 28/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.7557 - R2: 0.3698 - val_loss: 1.7637 - val_R2: 0.3890\n","Epoch 29/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.7278 - R2: 0.3798 - val_loss: 1.7362 - val_R2: 0.3985\n","Epoch 30/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.7008 - R2: 0.3895 - val_loss: 1.7080 - val_R2: 0.4083\n","Epoch 31/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.6718 - R2: 0.3999 - val_loss: 1.6801 - val_R2: 0.4179\n","Epoch 32/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.6433 - R2: 0.4101 - val_loss: 1.6515 - val_R2: 0.4279\n","Epoch 33/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.6207 - R2: 0.4182 - val_loss: 1.6232 - val_R2: 0.4377\n","Epoch 34/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.5928 - R2: 0.4283 - val_loss: 1.5960 - val_R2: 0.4471\n","Epoch 35/2000\n","32/32 [==============================] - 46s 1s/step - loss: 1.5733 - R2: 0.4352 - val_loss: 1.5702 - val_R2: 0.4560\n","Epoch 36/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.5525 - R2: 0.4427 - val_loss: 1.5452 - val_R2: 0.4647\n","Epoch 37/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.5295 - R2: 0.4510 - val_loss: 1.5208 - val_R2: 0.4731\n","Epoch 38/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.5007 - R2: 0.4613 - val_loss: 1.4974 - val_R2: 0.4813\n","Epoch 39/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.4834 - R2: 0.4675 - val_loss: 1.4732 - val_R2: 0.4896\n","Epoch 40/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.4571 - R2: 0.4770 - val_loss: 1.4492 - val_R2: 0.4979\n","Epoch 41/2000\n","32/32 [==============================] - 46s 1s/step - loss: 1.4509 - R2: 0.4792 - val_loss: 1.4278 - val_R2: 0.5054\n","Epoch 42/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.4234 - R2: 0.4890 - val_loss: 1.4043 - val_R2: 0.5135\n","Epoch 43/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.4037 - R2: 0.4961 - val_loss: 1.3834 - val_R2: 0.5207\n","Epoch 44/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.3862 - R2: 0.5024 - val_loss: 1.3661 - val_R2: 0.5267\n","Epoch 45/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.3643 - R2: 0.5103 - val_loss: 1.3469 - val_R2: 0.5334\n","Epoch 46/2000\n","32/32 [==============================] - 46s 1s/step - loss: 1.3449 - R2: 0.5172 - val_loss: 1.3291 - val_R2: 0.5396\n","Epoch 47/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.3330 - R2: 0.5215 - val_loss: 1.3107 - val_R2: 0.5459\n","Epoch 48/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.3117 - R2: 0.5291 - val_loss: 1.2949 - val_R2: 0.5514\n","Epoch 49/2000\n","32/32 [==============================] - 46s 1s/step - loss: 1.2955 - R2: 0.5350 - val_loss: 1.2802 - val_R2: 0.5565\n","Epoch 50/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.2794 - R2: 0.5408 - val_loss: 1.2655 - val_R2: 0.5616\n","Epoch 51/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.2620 - R2: 0.5470 - val_loss: 1.2503 - val_R2: 0.5668\n","Epoch 52/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.2433 - R2: 0.5537 - val_loss: 1.2368 - val_R2: 0.5715\n","Epoch 53/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.2228 - R2: 0.5611 - val_loss: 1.2225 - val_R2: 0.5765\n","Epoch 54/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.2108 - R2: 0.5654 - val_loss: 1.2078 - val_R2: 0.5816\n","Epoch 55/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.1935 - R2: 0.5716 - val_loss: 1.1965 - val_R2: 0.5855\n","Epoch 56/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.1793 - R2: 0.5767 - val_loss: 1.1812 - val_R2: 0.5908\n","Epoch 57/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.1677 - R2: 0.5809 - val_loss: 1.1694 - val_R2: 0.5949\n","Epoch 58/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.1440 - R2: 0.5894 - val_loss: 1.1597 - val_R2: 0.5982\n","Epoch 59/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.1297 - R2: 0.5945 - val_loss: 1.1470 - val_R2: 0.6026\n","Epoch 60/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.1113 - R2: 0.6011 - val_loss: 1.1362 - val_R2: 0.6064\n","Epoch 61/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.0990 - R2: 0.6055 - val_loss: 1.1241 - val_R2: 0.6106\n","Epoch 62/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.0915 - R2: 0.6082 - val_loss: 1.1149 - val_R2: 0.6138\n","Epoch 63/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.0633 - R2: 0.6183 - val_loss: 1.1044 - val_R2: 0.6174\n","Epoch 64/2000\n","32/32 [==============================] - 46s 1s/step - loss: 1.0543 - R2: 0.6216 - val_loss: 1.0950 - val_R2: 0.6206\n","Epoch 65/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.0348 - R2: 0.6285 - val_loss: 1.0877 - val_R2: 0.6232\n","Epoch 66/2000\n","32/32 [==============================] - 44s 1s/step - loss: 1.0288 - R2: 0.6307 - val_loss: 1.0775 - val_R2: 0.6267\n","Epoch 67/2000\n","32/32 [==============================] - 45s 1s/step - loss: 1.0098 - R2: 0.6375 - val_loss: 1.0708 - val_R2: 0.6290\n","Epoch 68/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.9993 - R2: 0.6413 - val_loss: 1.0608 - val_R2: 0.6325\n","Epoch 69/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.9850 - R2: 0.6464 - val_loss: 1.0544 - val_R2: 0.6347\n","Epoch 70/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.9733 - R2: 0.6506 - val_loss: 1.0448 - val_R2: 0.6380\n","Epoch 71/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.9591 - R2: 0.6557 - val_loss: 1.0352 - val_R2: 0.6414\n","Epoch 72/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.9475 - R2: 0.6599 - val_loss: 1.0339 - val_R2: 0.6418\n","Epoch 73/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.9385 - R2: 0.6631 - val_loss: 1.0274 - val_R2: 0.6441\n","Epoch 74/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.9203 - R2: 0.6697 - val_loss: 1.0166 - val_R2: 0.6478\n","Epoch 75/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.9140 - R2: 0.6719 - val_loss: 1.0144 - val_R2: 0.6486\n","Epoch 76/2000\n","32/32 [==============================] - 43s 1s/step - loss: 0.9032 - R2: 0.6758 - val_loss: 1.0047 - val_R2: 0.6519\n","Epoch 77/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8893 - R2: 0.6808 - val_loss: 0.9968 - val_R2: 0.6547\n","Epoch 78/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.8813 - R2: 0.6836 - val_loss: 0.9928 - val_R2: 0.6560\n","Epoch 79/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8698 - R2: 0.6878 - val_loss: 0.9859 - val_R2: 0.6585\n","Epoch 80/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8695 - R2: 0.6879 - val_loss: 0.9797 - val_R2: 0.6606\n","Epoch 81/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8572 - R2: 0.6923 - val_loss: 0.9729 - val_R2: 0.6630\n","Epoch 82/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8473 - R2: 0.6958 - val_loss: 0.9665 - val_R2: 0.6651\n","Epoch 83/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8399 - R2: 0.6985 - val_loss: 0.9616 - val_R2: 0.6669\n","Epoch 84/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8335 - R2: 0.7008 - val_loss: 0.9587 - val_R2: 0.6679\n","Epoch 85/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.8222 - R2: 0.7049 - val_loss: 0.9532 - val_R2: 0.6698\n","Epoch 86/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.8189 - R2: 0.7061 - val_loss: 0.9499 - val_R2: 0.6709\n","Epoch 87/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.8040 - R2: 0.7114 - val_loss: 0.9464 - val_R2: 0.6721\n","Epoch 88/2000\n","32/32 [==============================] - 43s 1s/step - loss: 0.8053 - R2: 0.7109 - val_loss: 0.9426 - val_R2: 0.6734\n","Epoch 89/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7944 - R2: 0.7149 - val_loss: 0.9386 - val_R2: 0.6748\n","Epoch 90/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7848 - R2: 0.7183 - val_loss: 0.9354 - val_R2: 0.6759\n","Epoch 91/2000\n","32/32 [==============================] - 43s 1s/step - loss: 0.7869 - R2: 0.7175 - val_loss: 0.9329 - val_R2: 0.6768\n","Epoch 92/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7826 - R2: 0.7191 - val_loss: 0.9312 - val_R2: 0.6774\n","Epoch 93/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7729 - R2: 0.7226 - val_loss: 0.9248 - val_R2: 0.6796\n","Epoch 94/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7642 - R2: 0.7257 - val_loss: 0.9258 - val_R2: 0.6792\n","Epoch 95/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7652 - R2: 0.7253 - val_loss: 0.9283 - val_R2: 0.6784\n","Epoch 96/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7567 - R2: 0.7284 - val_loss: 0.9199 - val_R2: 0.6813\n","Epoch 97/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7509 - R2: 0.7305 - val_loss: 0.9210 - val_R2: 0.6809\n","Epoch 98/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7439 - R2: 0.7330 - val_loss: 0.9185 - val_R2: 0.6818\n","Epoch 99/2000\n","32/32 [==============================] - 43s 1s/step - loss: 0.7391 - R2: 0.7347 - val_loss: 0.9151 - val_R2: 0.6830\n","Epoch 100/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7355 - R2: 0.7360 - val_loss: 0.9168 - val_R2: 0.6824\n","Epoch 101/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7279 - R2: 0.7387 - val_loss: 0.9171 - val_R2: 0.6823\n","Epoch 102/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7326 - R2: 0.7370 - val_loss: 0.9103 - val_R2: 0.6846\n","Epoch 103/2000\n","32/32 [==============================] - 43s 1s/step - loss: 0.7224 - R2: 0.7407 - val_loss: 0.9055 - val_R2: 0.6863\n","Epoch 104/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7208 - R2: 0.7413 - val_loss: 0.9107 - val_R2: 0.6845\n","Epoch 105/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7117 - R2: 0.7445 - val_loss: 0.9083 - val_R2: 0.6853\n","Epoch 106/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7187 - R2: 0.7420 - val_loss: 0.9080 - val_R2: 0.6854\n","Epoch 107/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.7071 - R2: 0.7462 - val_loss: 0.9073 - val_R2: 0.6857\n","Epoch 108/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7029 - R2: 0.7477 - val_loss: 0.9022 - val_R2: 0.6874\n","Epoch 109/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.7036 - R2: 0.7475 - val_loss: 0.9044 - val_R2: 0.6867\n","Epoch 110/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6978 - R2: 0.7495 - val_loss: 0.9006 - val_R2: 0.6880\n","Epoch 111/2000\n","32/32 [==============================] - 43s 1s/step - loss: 0.6945 - R2: 0.7507 - val_loss: 0.9056 - val_R2: 0.6863\n","Epoch 112/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6904 - R2: 0.7522 - val_loss: 0.8988 - val_R2: 0.6886\n","Epoch 113/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6939 - R2: 0.7509 - val_loss: 0.8961 - val_R2: 0.6896\n","Epoch 114/2000\n","32/32 [==============================] - 43s 1s/step - loss: 0.6859 - R2: 0.7538 - val_loss: 0.8986 - val_R2: 0.6887\n","Epoch 115/2000\n","32/32 [==============================] - 46s 1s/step - loss: 0.6833 - R2: 0.7547 - val_loss: 0.8950 - val_R2: 0.6899\n","Epoch 116/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6816 - R2: 0.7553 - val_loss: 0.8918 - val_R2: 0.6910\n","Epoch 117/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6790 - R2: 0.7563 - val_loss: 0.8947 - val_R2: 0.6900\n","Epoch 118/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6734 - R2: 0.7583 - val_loss: 0.8908 - val_R2: 0.6914\n","Epoch 119/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6719 - R2: 0.7588 - val_loss: 0.8930 - val_R2: 0.6906\n","Epoch 120/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6690 - R2: 0.7599 - val_loss: 0.8917 - val_R2: 0.6911\n","Epoch 121/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6744 - R2: 0.7579 - val_loss: 0.8914 - val_R2: 0.6912\n","Epoch 122/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6642 - R2: 0.7616 - val_loss: 0.8879 - val_R2: 0.6924\n","Epoch 123/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6620 - R2: 0.7624 - val_loss: 0.8877 - val_R2: 0.6925\n","Epoch 124/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6583 - R2: 0.7637 - val_loss: 0.8909 - val_R2: 0.6914\n","Epoch 125/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6542 - R2: 0.7652 - val_loss: 0.8897 - val_R2: 0.6918\n","Epoch 126/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6539 - R2: 0.7653 - val_loss: 0.8864 - val_R2: 0.6929\n","Epoch 127/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6560 - R2: 0.7645 - val_loss: 0.8855 - val_R2: 0.6932\n","Epoch 128/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6543 - R2: 0.7651 - val_loss: 0.8869 - val_R2: 0.6928\n","Epoch 129/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6475 - R2: 0.7676 - val_loss: 0.8877 - val_R2: 0.6924\n","Epoch 130/2000\n","32/32 [==============================] - 46s 1s/step - loss: 0.6477 - R2: 0.7675 - val_loss: 0.8885 - val_R2: 0.6922\n","Epoch 131/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6408 - R2: 0.7700 - val_loss: 0.8861 - val_R2: 0.6930\n","Epoch 132/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6430 - R2: 0.7692 - val_loss: 0.8884 - val_R2: 0.6922\n","Epoch 133/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6412 - R2: 0.7698 - val_loss: 0.8857 - val_R2: 0.6932\n","Epoch 134/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6368 - R2: 0.7714 - val_loss: 0.8849 - val_R2: 0.6934\n","Epoch 135/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6316 - R2: 0.7733 - val_loss: 0.8871 - val_R2: 0.6927\n","Epoch 136/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6299 - R2: 0.7739 - val_loss: 0.8807 - val_R2: 0.6949\n","Epoch 137/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6297 - R2: 0.7740 - val_loss: 0.8834 - val_R2: 0.6940\n","Epoch 138/2000\n","32/32 [==============================] - 46s 1s/step - loss: 0.6221 - R2: 0.7767 - val_loss: 0.8826 - val_R2: 0.6942\n","Epoch 139/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6253 - R2: 0.7755 - val_loss: 0.8790 - val_R2: 0.6955\n","Epoch 140/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6244 - R2: 0.7759 - val_loss: 0.8813 - val_R2: 0.6947\n","Epoch 141/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6216 - R2: 0.7769 - val_loss: 0.8854 - val_R2: 0.6932\n","Epoch 142/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6166 - R2: 0.7786 - val_loss: 0.8799 - val_R2: 0.6952\n","Epoch 143/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6225 - R2: 0.7766 - val_loss: 0.8839 - val_R2: 0.6938\n","Epoch 144/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6219 - R2: 0.7768 - val_loss: 0.8814 - val_R2: 0.6946\n","Epoch 145/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6159 - R2: 0.7789 - val_loss: 0.8832 - val_R2: 0.6940\n","Epoch 146/2000\n","32/32 [==============================] - 44s 1s/step - loss: 0.6097 - R2: 0.7811 - val_loss: 0.8817 - val_R2: 0.6945\n","Epoch 147/2000\n","32/32 [==============================] - 45s 1s/step - loss: 0.6129 - R2: 0.7800 - val_loss: 0.8805 - val_R2: 0.6950\n","Epoch 148/2000\n"," 3/32 [=>............................] - ETA: 36s - loss: 0.6049 - R2: 0.7829"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OzJFUajdcRud"},"source":[""],"execution_count":null,"outputs":[]}]}