{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_deepLearning.ipynb","provenance":[],"collapsed_sections":["WD9ifxG6K1Rt"]},"kernelspec":{"name":"python3","display_name":"Python 3.7.10 64-bit ('orca_test': conda)"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"c879f6fdfda01e8e78288223f6259a000d2b0c9a81de8f400c7147f1b544ea6a"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-uVWZw91DBd","executionInfo":{"status":"ok","timestamp":1628781830902,"user_tz":180,"elapsed":10685,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"3110f0f5-550d-453a-eb44-51fce1a95822"},"source":["%load_ext autoreload\n","%autoreload 2\n","import os.path\n","\n","path = ''\n","if not os.path.isfile('001_Data_retrieve.ipynb'):\n","    !pip install -U -q PyDrive\n","    from pydrive.auth import GoogleAuth\n","    from pydrive.drive import GoogleDrive\n","    from google.colab import auth\n","    from oauth2client.client import GoogleCredentials\n","\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    path = '/content/drive/MyDrive/TRABAJO/Data Science/ITBA-DeepLearning/Notebooks/TP-FINAL/bioinformatics_final_project/'\n","    !pip install rdkit-pypi\n","    !pip install git+https://github.com/EBjerrum/molvecgen\n","\n","    #auth.authenticate_user()\n","    #gauth = GoogleAuth()\n","    #gauth.credentials = GoogleCredentials.get_application_default()\n","    #drive = GoogleDrive(gauth)\n","    #downloaded = drive.CreateFile({'id':'10fMCM9wnmjlyGwiyNzpfPROExiq8ukKk'})\n","    #downloaded.GetContentFile('dataaug.py')\n","    #downloaded = drive.CreateFile({'id':'1jPB1HDpGN5zFRuhqN6b9RLMuuUQy0UoB'})\n","    #downloaded.GetContentFile('datagen.py')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.7/dist-packages (2021.3.4)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n","Collecting git+https://github.com/EBjerrum/molvecgen\n","  Cloning https://github.com/EBjerrum/molvecgen to /tmp/pip-req-build-2q6ppjwa\n","  Running command git clone -q https://github.com/EBjerrum/molvecgen /tmp/pip-req-build-2q6ppjwa\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from molvecgen==0.1) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eER-T2hURHH6"},"source":["#!wget https://raw.githubusercontent.com/EBjerrum/SMILES-enumeration/master/SmilesEnumerator.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ebAggDM1MoI"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","#from datagen import smiles_dict, smiles_to_seq\n","#from dataaug import SmilesEnumerator, SmilesIterator\n","from molvecgen import SmilesVectorizer,SmilesGenerator\n","from rdkit import Chem\n","from rdkit.Chem.Draw import IPythonConsole\n","\n","\n","from tensorflow.keras import Sequential,regularizers, Model\n","from tensorflow.keras.layers import InputLayer,LSTM, Dense, Embedding, Bidirectional, Dropout, Activation, BatchNormalization, Conv1D, MaxPool1D, Reshape\n","from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, Flatten, Input, Concatenate,RepeatVector,TimeDistributed,Multiply,Lambda\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.activations import softmax\n","\n","\n","\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mn8DHAowg7-"},"source":["#Mertrica del Problema\n","def R2(y_true, y_pred):\n","    SS_res =  K.sum(K.square( y_true-y_pred ))\n","    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n","    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n","\n","def R2_numpy(y_true, y_pred):\n","    SS_res =  np.sum(np.square( y_true-y_pred ))\n","    SS_tot = np.sum(np.square( y_true - np.mean(y_true) ) )\n","    return ( 1 - SS_res/(SS_tot + np.finfo(float).eps ) )\n","\n","#Callbacks\n","earlystop = EarlyStopping(monitor='val_R2', min_delta=0, patience=100, verbose=2)\n","mcp = ModelCheckpoint(path+'models/best_model', monitor='val_R2', mode='max', save_best_only=True, save_format=\"h5\")\n","tensorboard_callback = TensorBoard(log_dir=path+'fit_tensorboard/'+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PHOL_N1d4n0x"},"source":["## Carga de Datos y Split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7onZXBf1Vw2","executionInfo":{"status":"ok","timestamp":1628732593903,"user_tz":180,"elapsed":3318,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"5f3f88b0-13ab-471a-e26a-6be07970f15f"},"source":["df = pd.read_csv(path+'data/acetylcholinesterase_02_bioactivity_data_preprocessed.csv')\n","max_len_idx = df['canonical_smiles'].apply(len).argmax()\n","min_len_idx = df['canonical_smiles'].apply(len).argmin()\n","max_sequence_len = len(df['canonical_smiles'].iloc[max_len_idx]) + 20\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>molecule_chembl_id</th>\n","      <th>canonical_smiles</th>\n","      <th>standard_value</th>\n","      <th>standard_value_norm</th>\n","      <th>pIC50</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CHEMBL133897</td>\n","      <td>CCOc1nn(-c2cccc(OCc3ccccc3)c2)c(=O)o1</td>\n","      <td>750.0</td>\n","      <td>750.0</td>\n","      <td>6.124939</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CHEMBL336398</td>\n","      <td>O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC1CC1</td>\n","      <td>100.0</td>\n","      <td>100.0</td>\n","      <td>7.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CHEMBL131588</td>\n","      <td>CN(C(=O)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F)c1ccccc1</td>\n","      <td>50000.0</td>\n","      <td>50000.0</td>\n","      <td>4.301030</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CHEMBL130628</td>\n","      <td>O=C(N1CCCCC1)n1nc(-c2ccc(Cl)cc2)nc1SCC(F)(F)F</td>\n","      <td>300.0</td>\n","      <td>300.0</td>\n","      <td>6.522879</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CHEMBL130478</td>\n","      <td>CSc1nc(-c2ccc(OC(F)(F)F)cc2)nn1C(=O)N(C)C</td>\n","      <td>800.0</td>\n","      <td>800.0</td>\n","      <td>6.096910</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  molecule_chembl_id  ...     pIC50\n","0       CHEMBL133897  ...  6.124939\n","1       CHEMBL336398  ...  7.000000\n","2       CHEMBL131588  ...  4.301030\n","3       CHEMBL130628  ...  6.522879\n","4       CHEMBL130478  ...  6.096910\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"vnS8hmok3GxZ"},"source":["#Seleccion de Inputs y Outputs\n","X = df['canonical_smiles'].values\n","y = df['pIC50'].values\n","#Split de Datos\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","batch_size = 250"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SvXIz4_yW34n","executionInfo":{"status":"ok","timestamp":1628693010544,"user_tz":180,"elapsed":3321,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"cfe2db1f-ea51-4768-d807-83890a0b91aa"},"source":["### USANDO LA LIB molvecgen\n","mols_all = [Chem.MolFromSmiles(smile) for smile in X]\n","sm_train = SmilesVectorizer(canonical=True, augment=True, leftpad=True)\n","sm_test = SmilesVectorizer(canonical=True, augment=False, leftpad=True)\n","sm_train.fit(mols_all) #, extra_chars=['9'])  \n","sm_test.fit(mols_all) #, extra_chars=['9'])\n","\n","#Paso de String a Mols\n","mols_train = [Chem.MolFromSmiles(smile) for smile in X_train]\n","mols_test = [Chem.MolFromSmiles(smile) for smile in X_test]\n","\n","#Creo los Generators\n","generator = SmilesGenerator(mols_train,y_train,sm_train, batch_size=batch_size, shuffle=True)\n","generatorTest = SmilesGenerator(mols_test,y_test,sm_test, batch_size=batch_size, shuffle=True)\n","\n","#Chequeo\n","batch_x, batch_y = generator.next()\n","print(batch_x.shape)\n","print(batch_y.shape)\n","print(batch_y)\n","plt.matshow(batch_x[0].T)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(250, 217, 41)\n","(250,)\n","[ 9.28399666  2.30103     3.06048075  7.03338901  3.34103516  6.40560745\n","  7.07417243  6.51999306  5.50863831  7.90657831  6.75448733  6.20551195\n","  4.          3.41166105  4.91009489  6.40893539  4.97510404  6.19111413\n","  4.48017201  5.0872467   7.          7.          6.67778071  6.94692156\n","  5.25181197  6.51570016  5.73992861  6.05060999  3.61546738  6.79588002\n","  6.84466396  7.09691001  6.33724217  4.52578374  5.60032628  8.79588002\n","  6.74472749  6.14874165  4.69897     7.66554625  3.88239731  7.16178078\n","  4.46852108  5.68824614  6.95663772  9.34678749  6.58004425  6.24412514\n","  5.08777794  5.39469495  5.41453927  3.59694815  7.15490196  7.04963515\n","  4.7235382   5.98296666  6.76955108  6.2636035   4.16749109  3.75945075\n","  3.          7.73754891  6.18045606  3.40893539  6.7721133   6.\n","  7.19928292  7.9625735   5.30103     6.05060999  5.47366072  5.54060751\n","  5.45099674  4.05060999  4.61350103  6.4202164   6.90308999  3.81815641\n","  4.45593196  5.30103     6.11463878  6.82390874  4.75202673  5.22257318\n","  4.20065945  5.22184875  7.7212464   8.89008414  6.91364017  9.02227639\n","  5.4202164   9.52287875  4.69897     4.18495382  6.89075903  4.\n","  6.55284197  5.74472749  7.52287875  7.60205999  7.92081875  3.30103\n","  6.27000145  8.52287875  7.37468755  5.50307035  5.29242982  4.82102305\n","  4.24412514  7.8569852   7.25181197  7.99567863  5.76955108  8.\n","  6.838632    8.          5.4723701   9.32002731  5.01010544  7.63997491\n","  4.69897     4.52287875  8.82973828  5.74958     6.92081875  5.30980392\n","  6.49485002  5.84771166  6.00877392  4.          4.55284197  4.92081875\n","  4.33724217  4.537602    3.30103     7.17652577  5.          4.95428594\n","  4.21467016  7.          6.09691001  5.90308999  5.67366414  7.02687215\n","  5.96999972  5.22767829  8.87942607  5.65757732  6.04431225  6.11918641\n","  5.838632    4.64975198  5.95860731  4.84649001  4.69897     8.48004082\n"," -5.27        3.86327943  6.16115091  6.84499816  5.05799195  7.65757732\n","  5.81247928  8.28399666  5.20481541  4.99567863  8.51570016  4.30103\n","  6.51215488  5.23582387  5.59516628  6.7721133   7.66154351  7.47146894\n","  6.45469288  5.67778071  4.69897     7.          7.63827216  4.26760624\n","  9.36653154  6.09044397  5.46470588  2.67778071  3.69897     5.33287406\n","  7.19382003  6.          5.09691001  4.30103     6.64589156  5.67778071\n","  5.36653154  7.04383157  4.76598918  6.13076828  6.65364703  4.14569396\n","  5.66756154  4.61618463  5.4202164   4.57348874  5.30980392  6.\n","  6.04575749  2.30277066  5.4202164   8.28819277  5.74958     4.35753548\n","  8.63827216  4.76999991  7.44977165  5.13667714  8.30364361  4.\n","  7.60205999  5.65915945  6.38721614  7.09691001  4.10623824  6.33724217\n","  2.66756154 10.57105571  6.28399666  5.537602    6.          7.65757732\n","  5.43179828  3.9788107   4.73565449  5.25963731  4.61385789  3.00436481\n","  6.79588002  5.20760831  5.29499204  6.95860731  8.627088    7.4202164\n","  5.7212464   4.39794001  5.86012091  4.92811799  6.03526908  3.58502665\n","  6.75448733  8.48545225  4.          7.20760831]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fbc9b2abed0>"]},"metadata":{"tags":[]},"execution_count":29},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1152x217.659 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"27w7sHoY3yIf"},"source":["### USANDO LA LIB SMILES-enumeration # La lib creo que tiene algunos issues, al final es mejor la molvecgen\n","  #sme = SmilesEnumerator()\n","  #smeTest = SmilesEnumerator(enum=False) \n","  #sme.fit(df['canonical_smiles'])\n","  #smeTest.fit(df['canonical_smiles'])\n","#No aparece en vocabulario el caracter '9' cuando se hace el fit, por eso lo tengo que hacer manualmente \n","  #sme._char_to_int.update({'9': 38})\n","  #sme._charlen=39\n","  #smeTest._char_to_int.update({'9': 38})\n","  #smeTest._charlen=39\n","## Ver porque no funciona \"bien\" la lib o si se puede hacer de otra forma.\n","\n","  #sme.leftpad= True\n","  #smeTest.leftpad= True\n","\n","  #generator = SmilesIterator(X_train, y_train, sme, batch_size=250, shuffle=True, dtype=K.floatx())\n","  #generatorTest = SmilesIterator(X_test, y_test, smeTest, batch_size=250, shuffle=False, dtype=K.floatx())\n","\n","# Esto era cuando no me habia dado cuenta que el generator de la lib no tiene encuenta la cantidad de datos, y genera batchs infinitamente.\n","  #X_trainG,y_trainG = generator.next()\n","  #X_testG,y_testG = generatorTest.next()\n","\n","  #print(X_train.shape, X_test.shape)\n","  #print(X_trainG.shape, X_testG.shape)\n","  #plt.imshow(X_trainG[1])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFI6Tp4lK5W3"},"source":["# INPUTS CON SMILES VECTORIZADOS CON DATA AUGMENTATION"]},{"cell_type":"code","metadata":{"id":"Ywm-eRYCgad5"},"source":["#Parametros - Hiper-parametros Generales\n","x_temp, y_temp = generator.next()\n","input_shape = x_temp.shape[1:]\n","output_shape = 1\n","train_step = round(y_train.shape[0]/batch_size)\n","validation_step = round(y_test.shape[0]/batch_size)\n","lstm_dropout = 0.19\n","l1 = 0.005\n","l2 = 0.01\n","learning_rate=0.005\n","cant_neuronas_lstm = 64\n","cant_neuronas_hidden_layer = 100\n","\n","FILTER_SIZES = (3, 4, 5)\n","NUM_FILTERS = 64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WD9ifxG6K1Rt"},"source":["## **PRUEBA-1** Smiles Vectorizados - LSTM\n","-Mejor R2 de Validacion logrado= 0.68"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQO-aczY-lf9","executionInfo":{"status":"ok","timestamp":1628609466174,"user_tz":180,"elapsed":1046,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"4dd8a909-fdb3-4d22-fa98-c84ed691e62a"},"source":["# Modelo\n","model = Sequential()\n","model.add(LSTM(cant_neuronas_lstm,\n","               input_shape=input_shape,\n","               dropout = lstm_dropout\n","               #unroll= True\n","              ))\n","model.add(Dense(output_shape,\n","                kernel_regularizer=regularizers.l1_l2(l1,l2),\n","                activation=\"linear\"))\n","\n","model.compile(loss=\"mse\", optimizer=RMSprop(learning_rate=learning_rate),  metrics=[R2])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_1 (LSTM)                (None, 64)                27136     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 27,201\n","Trainable params: 27,201\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SfYJ6f6D10le"},"source":["#from tensorflow.python.framework.ops import disable_eager_execution\n","#disable_eager_execution()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x1esj0IZ-we-","executionInfo":{"status":"ok","timestamp":1628609017902,"user_tz":180,"elapsed":347458,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"867ad40d-fa60-4689-a324-2007cc25de4a"},"source":["#model.fit(generator,  epochs=2000, validation_data=generatorTest, steps_per_epoch=20,  callbacks=[earlystop, mcp] )\n","model.fit(generator, validation_data=generatorTest, steps_per_epoch=train_step, validation_steps=validation_step , epochs=2000, callbacks=[earlystop] )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2000\n","16/16 [==============================] - 10s 139ms/step - loss: 6.8594 - R2: -1.4462 - val_loss: 2.9740 - val_R2: -0.0064\n","Epoch 2/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 2.9015 - R2: -0.0395 - val_loss: 3.1556 - val_R2: -0.0630\n","Epoch 3/2000\n","16/16 [==============================] - 2s 105ms/step - loss: 2.9458 - R2: -0.0315 - val_loss: 3.0846 - val_R2: -0.0413\n","Epoch 4/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.9057 - R2: -0.0170 - val_loss: 2.9461 - val_R2: -7.6011e-04\n","Epoch 5/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 2.9074 - R2: -0.0215 - val_loss: 2.9367 - val_R2: 0.0055\n","Epoch 6/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.8658 - R2: -0.0181 - val_loss: 2.9023 - val_R2: 0.0170\n","Epoch 7/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 2.9055 - R2: -7.9785e-04 - val_loss: 2.9696 - val_R2: 0.0018\n","Epoch 8/2000\n","16/16 [==============================] - 2s 105ms/step - loss: 2.8042 - R2: -0.0143 - val_loss: 2.9800 - val_R2: -0.0094\n","Epoch 9/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 2.7529 - R2: -0.0025 - val_loss: 2.8219 - val_R2: 0.0136\n","Epoch 10/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.7586 - R2: -0.0040 - val_loss: 2.8786 - val_R2: 0.0309\n","Epoch 11/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 3.0105 - R2: 0.0024 - val_loss: 2.9185 - val_R2: 0.0162\n","Epoch 12/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.7095 - R2: 0.0067 - val_loss: 2.8217 - val_R2: 0.0385\n","Epoch 13/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.8325 - R2: 0.0141 - val_loss: 2.7929 - val_R2: 0.0520\n","Epoch 14/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 2.8854 - R2: 0.0059 - val_loss: 2.7349 - val_R2: 0.0486\n","Epoch 15/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.7868 - R2: 0.0066 - val_loss: 2.7740 - val_R2: 0.0583\n","Epoch 16/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.7431 - R2: 0.0168 - val_loss: 2.7557 - val_R2: 0.0677\n","Epoch 17/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.8147 - R2: -0.0245 - val_loss: 2.7771 - val_R2: 0.0561\n","Epoch 18/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.7905 - R2: 0.0325 - val_loss: 2.7896 - val_R2: 0.0626\n","Epoch 19/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.7142 - R2: 0.0361 - val_loss: 3.1002 - val_R2: -0.0605\n","Epoch 20/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.7814 - R2: 0.0206 - val_loss: 2.7713 - val_R2: 0.0652\n","Epoch 21/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 2.6990 - R2: 0.0428 - val_loss: 3.1890 - val_R2: -0.1019\n","Epoch 22/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 3.5237 - R2: -0.1971 - val_loss: 2.5903 - val_R2: 0.0686\n","Epoch 23/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 2.6768 - R2: 0.0283 - val_loss: 2.7657 - val_R2: 0.0600\n","Epoch 24/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.7645 - R2: 0.0593 - val_loss: 2.7569 - val_R2: 0.0658\n","Epoch 25/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.6977 - R2: 0.0540 - val_loss: 2.7029 - val_R2: 0.0872\n","Epoch 26/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 2.5905 - R2: 0.0506 - val_loss: 2.7419 - val_R2: 0.0799\n","Epoch 27/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.6916 - R2: 0.0467 - val_loss: 2.7682 - val_R2: 0.0560\n","Epoch 28/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.7126 - R2: 0.0640 - val_loss: 2.7779 - val_R2: 0.0599\n","Epoch 29/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.7213 - R2: 0.0462 - val_loss: 2.6957 - val_R2: 0.0897\n","Epoch 30/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.7249 - R2: 0.0462 - val_loss: 4.9347 - val_R2: -0.7019\n","Epoch 31/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.7636 - R2: 0.0335 - val_loss: 2.6828 - val_R2: 0.1049\n","Epoch 32/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.6308 - R2: 0.0433 - val_loss: 2.6611 - val_R2: 0.0787\n","Epoch 33/2000\n","16/16 [==============================] - 2s 104ms/step - loss: 2.6826 - R2: 0.0817 - val_loss: 2.7083 - val_R2: 0.0865\n","Epoch 34/2000\n","16/16 [==============================] - 2s 104ms/step - loss: 2.6429 - R2: 0.0519 - val_loss: 2.7334 - val_R2: 0.0724\n","Epoch 35/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.5739 - R2: 0.0900 - val_loss: 2.7114 - val_R2: 0.0879\n","Epoch 36/2000\n","16/16 [==============================] - 2s 104ms/step - loss: 2.6153 - R2: 0.0892 - val_loss: 2.8491 - val_R2: 0.0367\n","Epoch 37/2000\n","16/16 [==============================] - 2s 105ms/step - loss: 2.5802 - R2: 0.0844 - val_loss: 2.5933 - val_R2: 0.1193\n","Epoch 38/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.6259 - R2: 0.0798 - val_loss: 2.6923 - val_R2: 0.0845\n","Epoch 39/2000\n","16/16 [==============================] - 2s 103ms/step - loss: 2.6090 - R2: 0.0859 - val_loss: 2.6130 - val_R2: 0.1170\n","Epoch 40/2000\n","16/16 [==============================] - 2s 105ms/step - loss: 2.4550 - R2: 0.1169 - val_loss: 3.0710 - val_R2: -0.0571\n","Epoch 41/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.6082 - R2: 0.0992 - val_loss: 2.6949 - val_R2: 0.0907\n","Epoch 42/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 2.4275 - R2: 0.1304 - val_loss: 2.5651 - val_R2: 0.1257\n","Epoch 43/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.4613 - R2: 0.1147 - val_loss: 2.9060 - val_R2: 0.0165\n","Epoch 44/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 2.5609 - R2: 0.1222 - val_loss: 2.6697 - val_R2: 0.0921\n","Epoch 45/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 2.4046 - R2: 0.1451 - val_loss: 2.5010 - val_R2: 0.1580\n","Epoch 46/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 2.4458 - R2: 0.1224 - val_loss: 3.0486 - val_R2: -0.0311\n","Epoch 47/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 2.5709 - R2: 0.1541 - val_loss: 2.3070 - val_R2: 0.2116\n","Epoch 48/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.3882 - R2: 0.1543 - val_loss: 2.3492 - val_R2: 0.2057\n","Epoch 49/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.2534 - R2: 0.1966 - val_loss: 2.3252 - val_R2: 0.2196\n","Epoch 50/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.3459 - R2: 0.1819 - val_loss: 2.3168 - val_R2: 0.2249\n","Epoch 51/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 2.2091 - R2: 0.2000 - val_loss: 2.2223 - val_R2: 0.2344\n","Epoch 52/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.2046 - R2: 0.2350 - val_loss: 2.3467 - val_R2: 0.2247\n","Epoch 53/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.5121 - R2: 0.1104 - val_loss: 2.4625 - val_R2: 0.1611\n","Epoch 54/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 2.5250 - R2: 0.1267 - val_loss: 2.4648 - val_R2: 0.1789\n","Epoch 55/2000\n","16/16 [==============================] - 2s 114ms/step - loss: 2.3491 - R2: 0.1832 - val_loss: 2.3962 - val_R2: 0.1996\n","Epoch 56/2000\n","16/16 [==============================] - 2s 113ms/step - loss: 2.1701 - R2: 0.2227 - val_loss: 2.7135 - val_R2: 0.0820\n","Epoch 57/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.4310 - R2: 0.1629 - val_loss: 2.2856 - val_R2: 0.2370\n","Epoch 58/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 2.1857 - R2: 0.2183 - val_loss: 2.3589 - val_R2: 0.2095\n","Epoch 59/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.2362 - R2: 0.2451 - val_loss: 2.1716 - val_R2: 0.2747\n","Epoch 60/2000\n","16/16 [==============================] - 2s 115ms/step - loss: 2.1739 - R2: 0.2158 - val_loss: 2.1199 - val_R2: 0.2769\n","Epoch 61/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 2.0905 - R2: 0.2443 - val_loss: 2.0940 - val_R2: 0.3045\n","Epoch 62/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 2.4756 - R2: 0.1402 - val_loss: 2.2703 - val_R2: 0.2393\n","Epoch 63/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.0726 - R2: 0.2967 - val_loss: 2.0623 - val_R2: 0.2977\n","Epoch 64/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.9965 - R2: 0.3074 - val_loss: 2.3247 - val_R2: 0.2280\n","Epoch 65/2000\n","16/16 [==============================] - 2s 113ms/step - loss: 2.0621 - R2: 0.2876 - val_loss: 2.0423 - val_R2: 0.3161\n","Epoch 66/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 1.9889 - R2: 0.3156 - val_loss: 2.0679 - val_R2: 0.3071\n","Epoch 67/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 1.8434 - R2: 0.3270 - val_loss: 2.0629 - val_R2: 0.3138\n","Epoch 68/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 2.0118 - R2: 0.3194 - val_loss: 1.9562 - val_R2: 0.3460\n","Epoch 69/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 1.9870 - R2: 0.3005 - val_loss: 2.1068 - val_R2: 0.2980\n","Epoch 70/2000\n","16/16 [==============================] - 2s 105ms/step - loss: 1.8731 - R2: 0.3537 - val_loss: 1.9992 - val_R2: 0.3339\n","Epoch 71/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.8901 - R2: 0.3486 - val_loss: 1.9313 - val_R2: 0.3497\n","Epoch 72/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 1.9533 - R2: 0.3389 - val_loss: 2.0343 - val_R2: 0.3118\n","Epoch 73/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.8789 - R2: 0.3620 - val_loss: 1.9254 - val_R2: 0.3578\n","Epoch 74/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.7348 - R2: 0.3727 - val_loss: 1.8363 - val_R2: 0.3898\n","Epoch 75/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 1.8335 - R2: 0.3898 - val_loss: 1.9253 - val_R2: 0.3582\n","Epoch 76/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.7148 - R2: 0.3980 - val_loss: 1.8623 - val_R2: 0.3815\n","Epoch 77/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.8586 - R2: 0.3635 - val_loss: 1.7465 - val_R2: 0.4092\n","Epoch 78/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.8182 - R2: 0.3882 - val_loss: 1.7580 - val_R2: 0.4086\n","Epoch 79/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.6641 - R2: 0.4210 - val_loss: 1.7801 - val_R2: 0.3946\n","Epoch 80/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.7256 - R2: 0.4070 - val_loss: 1.8292 - val_R2: 0.3754\n","Epoch 81/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.6279 - R2: 0.4217 - val_loss: 1.8718 - val_R2: 0.3759\n","Epoch 82/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.6920 - R2: 0.4225 - val_loss: 1.7006 - val_R2: 0.4171\n","Epoch 83/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.7587 - R2: 0.4056 - val_loss: 1.7395 - val_R2: 0.4241\n","Epoch 84/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.6982 - R2: 0.4153 - val_loss: 1.7101 - val_R2: 0.4344\n","Epoch 85/2000\n","16/16 [==============================] - 2s 113ms/step - loss: 1.5892 - R2: 0.4475 - val_loss: 1.6235 - val_R2: 0.4706\n","Epoch 86/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.5878 - R2: 0.4653 - val_loss: 1.6447 - val_R2: 0.4514\n","Epoch 87/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.5325 - R2: 0.4650 - val_loss: 1.7981 - val_R2: 0.4010\n","Epoch 88/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.4923 - R2: 0.4850 - val_loss: 1.6362 - val_R2: 0.4586\n","Epoch 89/2000\n","16/16 [==============================] - 2s 113ms/step - loss: 1.6215 - R2: 0.4487 - val_loss: 1.5852 - val_R2: 0.4648\n","Epoch 90/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.5580 - R2: 0.4701 - val_loss: 1.6463 - val_R2: 0.4469\n","Epoch 91/2000\n","16/16 [==============================] - 2s 115ms/step - loss: 1.5305 - R2: 0.4605 - val_loss: 1.6097 - val_R2: 0.4685\n","Epoch 92/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.5130 - R2: 0.4852 - val_loss: 1.5487 - val_R2: 0.4833\n","Epoch 93/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.5875 - R2: 0.4711 - val_loss: 1.6263 - val_R2: 0.4625\n","Epoch 94/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.4500 - R2: 0.4931 - val_loss: 1.5873 - val_R2: 0.4705\n","Epoch 95/2000\n","16/16 [==============================] - 2s 116ms/step - loss: 1.5182 - R2: 0.4705 - val_loss: 1.5960 - val_R2: 0.4734\n","Epoch 96/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.4380 - R2: 0.5197 - val_loss: 1.5665 - val_R2: 0.4687\n","Epoch 97/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.4603 - R2: 0.4801 - val_loss: 1.5857 - val_R2: 0.4743\n","Epoch 98/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.4997 - R2: 0.5065 - val_loss: 1.5076 - val_R2: 0.5038\n","Epoch 99/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.4044 - R2: 0.5227 - val_loss: 6.1129 - val_R2: -1.1230\n","Epoch 100/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 2.6896 - R2: 0.0353 - val_loss: 1.7179 - val_R2: 0.4243\n","Epoch 101/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.5336 - R2: 0.4806 - val_loss: 1.6164 - val_R2: 0.4610\n","Epoch 102/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.4328 - R2: 0.5015 - val_loss: 1.5111 - val_R2: 0.5021\n","Epoch 103/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 1.4207 - R2: 0.5123 - val_loss: 1.5986 - val_R2: 0.4716\n","Epoch 104/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.4581 - R2: 0.5061 - val_loss: 1.5560 - val_R2: 0.4853\n","Epoch 105/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.3994 - R2: 0.5171 - val_loss: 1.5279 - val_R2: 0.4944\n","Epoch 106/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 1.4236 - R2: 0.5261 - val_loss: 1.5732 - val_R2: 0.4772\n","Epoch 107/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 1.3713 - R2: 0.5094 - val_loss: 1.4715 - val_R2: 0.5128\n","Epoch 108/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 1.4104 - R2: 0.5280 - val_loss: 1.5235 - val_R2: 0.4899\n","Epoch 109/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.3469 - R2: 0.5373 - val_loss: 1.3836 - val_R2: 0.5457\n","Epoch 110/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.3491 - R2: 0.5431 - val_loss: 1.3638 - val_R2: 0.5523\n","Epoch 111/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.2937 - R2: 0.5505 - val_loss: 1.4638 - val_R2: 0.5078\n","Epoch 112/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.3722 - R2: 0.5558 - val_loss: 1.3804 - val_R2: 0.5311\n","Epoch 113/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.3965 - R2: 0.5215 - val_loss: 1.4810 - val_R2: 0.5001\n","Epoch 114/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.2116 - R2: 0.5547 - val_loss: 1.4242 - val_R2: 0.5288\n","Epoch 115/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 1.3510 - R2: 0.5544 - val_loss: 1.3400 - val_R2: 0.5590\n","Epoch 116/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.2166 - R2: 0.5877 - val_loss: 1.3172 - val_R2: 0.5683\n","Epoch 117/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.3292 - R2: 0.5432 - val_loss: 1.3637 - val_R2: 0.5469\n","Epoch 118/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.2270 - R2: 0.5726 - val_loss: 1.5760 - val_R2: 0.4723\n","Epoch 119/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.2614 - R2: 0.5850 - val_loss: 1.4037 - val_R2: 0.5201\n","Epoch 120/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.2857 - R2: 0.5591 - val_loss: 1.3402 - val_R2: 0.5620\n","Epoch 121/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.2038 - R2: 0.5888 - val_loss: 1.4046 - val_R2: 0.5432\n","Epoch 122/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.2906 - R2: 0.5651 - val_loss: 1.3483 - val_R2: 0.5453\n","Epoch 123/2000\n","16/16 [==============================] - 2s 115ms/step - loss: 1.2611 - R2: 0.5730 - val_loss: 1.2085 - val_R2: 0.6067\n","Epoch 124/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.2045 - R2: 0.5997 - val_loss: 1.3010 - val_R2: 0.5813\n","Epoch 125/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.3095 - R2: 0.5505 - val_loss: 1.3653 - val_R2: 0.5486\n","Epoch 126/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.1989 - R2: 0.5910 - val_loss: 1.4254 - val_R2: 0.5341\n","Epoch 127/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.2274 - R2: 0.5864 - val_loss: 1.2897 - val_R2: 0.5756\n","Epoch 128/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.1005 - R2: 0.6209 - val_loss: 1.3604 - val_R2: 0.5488\n","Epoch 129/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.3007 - R2: 0.5583 - val_loss: 1.2487 - val_R2: 0.5992\n","Epoch 130/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 1.1863 - R2: 0.6256 - val_loss: 1.3692 - val_R2: 0.5634\n","Epoch 131/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.1592 - R2: 0.6022 - val_loss: 1.3158 - val_R2: 0.5676\n","Epoch 132/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.1331 - R2: 0.6002 - val_loss: 1.3135 - val_R2: 0.5794\n","Epoch 133/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.1788 - R2: 0.6117 - val_loss: 1.2460 - val_R2: 0.5963\n","Epoch 134/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.1321 - R2: 0.6080 - val_loss: 1.2525 - val_R2: 0.5953\n","Epoch 135/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.1527 - R2: 0.6345 - val_loss: 1.3733 - val_R2: 0.5489\n","Epoch 136/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.0981 - R2: 0.6112 - val_loss: 1.3065 - val_R2: 0.5763\n","Epoch 137/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.1262 - R2: 0.6366 - val_loss: 1.3741 - val_R2: 0.5546\n","Epoch 138/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.0543 - R2: 0.6547 - val_loss: 1.2192 - val_R2: 0.5801\n","Epoch 139/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.0912 - R2: 0.6406 - val_loss: 1.1503 - val_R2: 0.6212\n","Epoch 140/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.1125 - R2: 0.6297 - val_loss: 1.2776 - val_R2: 0.5784\n","Epoch 141/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.1057 - R2: 0.6349 - val_loss: 1.1768 - val_R2: 0.6159\n","Epoch 142/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 1.0484 - R2: 0.6444 - val_loss: 1.2016 - val_R2: 0.6103\n","Epoch 143/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.0223 - R2: 0.6591 - val_loss: 1.1986 - val_R2: 0.6133\n","Epoch 144/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.0148 - R2: 0.6598 - val_loss: 1.1647 - val_R2: 0.6242\n","Epoch 145/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.1124 - R2: 0.6405 - val_loss: 1.2442 - val_R2: 0.5926\n","Epoch 146/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 1.0599 - R2: 0.6442 - val_loss: 1.2152 - val_R2: 0.5885\n","Epoch 147/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.0574 - R2: 0.6424 - val_loss: 1.1817 - val_R2: 0.6244\n","Epoch 148/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.0231 - R2: 0.6647 - val_loss: 1.1360 - val_R2: 0.6392\n","Epoch 149/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.0816 - R2: 0.6506 - val_loss: 1.1570 - val_R2: 0.6020\n","Epoch 150/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.9816 - R2: 0.6609 - val_loss: 1.1647 - val_R2: 0.6162\n","Epoch 151/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.0547 - R2: 0.6582 - val_loss: 1.1264 - val_R2: 0.6340\n","Epoch 152/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 1.0530 - R2: 0.6597 - val_loss: 1.1348 - val_R2: 0.6300\n","Epoch 153/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.9825 - R2: 0.6715 - val_loss: 1.1178 - val_R2: 0.6435\n","Epoch 154/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.0047 - R2: 0.6869 - val_loss: 1.1338 - val_R2: 0.6323\n","Epoch 155/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.0267 - R2: 0.6607 - val_loss: 1.1702 - val_R2: 0.5770\n","Epoch 156/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.9574 - R2: 0.6880 - val_loss: 1.0854 - val_R2: 0.6497\n","Epoch 157/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 1.0095 - R2: 0.6709 - val_loss: 1.1280 - val_R2: 0.6446\n","Epoch 158/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.0236 - R2: 0.6669 - val_loss: 1.1599 - val_R2: 0.6312\n","Epoch 159/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 1.1720 - R2: 0.5980 - val_loss: 1.0897 - val_R2: 0.6471\n","Epoch 160/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.9628 - R2: 0.6915 - val_loss: 1.1432 - val_R2: 0.6148\n","Epoch 161/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 1.0419 - R2: 0.6641 - val_loss: 1.1674 - val_R2: 0.6201\n","Epoch 162/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 0.9535 - R2: 0.6861 - val_loss: 1.1400 - val_R2: 0.6385\n","Epoch 163/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.8918 - R2: 0.7016 - val_loss: 1.1841 - val_R2: 0.5939\n","Epoch 164/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 1.0413 - R2: 0.6611 - val_loss: 1.1512 - val_R2: 0.6290\n","Epoch 165/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.9454 - R2: 0.6882 - val_loss: 1.1473 - val_R2: 0.6273\n","Epoch 166/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.8904 - R2: 0.7042 - val_loss: 1.1894 - val_R2: 0.6114\n","Epoch 167/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.9410 - R2: 0.7006 - val_loss: 1.2173 - val_R2: 0.6101\n","Epoch 168/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.9910 - R2: 0.6813 - val_loss: 1.1463 - val_R2: 0.6320\n","Epoch 169/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 0.9475 - R2: 0.6778 - val_loss: 1.1879 - val_R2: 0.6230\n","Epoch 170/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 0.8955 - R2: 0.7249 - val_loss: 1.0650 - val_R2: 0.6482\n","Epoch 171/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.9367 - R2: 0.6874 - val_loss: 1.3156 - val_R2: 0.5592\n","Epoch 172/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 0.9528 - R2: 0.6931 - val_loss: 1.3728 - val_R2: 0.5613\n","Epoch 173/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.9513 - R2: 0.6910 - val_loss: 1.0909 - val_R2: 0.6538\n","Epoch 174/2000\n","16/16 [==============================] - 2s 113ms/step - loss: 0.9209 - R2: 0.7004 - val_loss: 1.0827 - val_R2: 0.6619\n","Epoch 175/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.8802 - R2: 0.7241 - val_loss: 1.1292 - val_R2: 0.6345\n","Epoch 176/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 0.8971 - R2: 0.7087 - val_loss: 1.2142 - val_R2: 0.6135\n","Epoch 177/2000\n","16/16 [==============================] - 2s 106ms/step - loss: 0.8790 - R2: 0.7092 - val_loss: 1.0915 - val_R2: 0.6606\n","Epoch 178/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 0.8546 - R2: 0.7222 - val_loss: 1.0502 - val_R2: 0.6685\n","Epoch 179/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.9480 - R2: 0.7120 - val_loss: 1.1110 - val_R2: 0.6499\n","Epoch 180/2000\n","16/16 [==============================] - 2s 105ms/step - loss: 0.8419 - R2: 0.7154 - val_loss: 1.1221 - val_R2: 0.6440\n","Epoch 181/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.9271 - R2: 0.6965 - val_loss: 1.1477 - val_R2: 0.6381\n","Epoch 182/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 0.8557 - R2: 0.7214 - val_loss: 1.1116 - val_R2: 0.6394\n","Epoch 183/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 0.8883 - R2: 0.7112 - val_loss: 1.1792 - val_R2: 0.6139\n","Epoch 184/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.8893 - R2: 0.7099 - val_loss: 1.0412 - val_R2: 0.6530\n","Epoch 185/2000\n","16/16 [==============================] - 2s 111ms/step - loss: 0.8380 - R2: 0.7418 - val_loss: 1.0311 - val_R2: 0.6797\n","Epoch 186/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 0.8863 - R2: 0.7148 - val_loss: 1.0662 - val_R2: 0.6617\n","Epoch 187/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.8485 - R2: 0.7293 - val_loss: 1.1573 - val_R2: 0.6233\n","Epoch 188/2000\n","16/16 [==============================] - 2s 110ms/step - loss: 0.8818 - R2: 0.7124 - val_loss: 1.0822 - val_R2: 0.6588\n","Epoch 189/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 0.8542 - R2: 0.7293 - val_loss: 1.0665 - val_R2: 0.6496\n","Epoch 190/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 0.8552 - R2: 0.7287 - val_loss: 1.6335 - val_R2: 0.4563\n","Epoch 191/2000\n","16/16 [==============================] - 2s 114ms/step - loss: 0.8944 - R2: 0.7168 - val_loss: 1.1496 - val_R2: 0.6364\n","Epoch 192/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 0.8694 - R2: 0.7117 - val_loss: 1.0568 - val_R2: 0.6561\n","Epoch 193/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.7817 - R2: 0.7397 - val_loss: 1.0918 - val_R2: 0.6539\n","Epoch 194/2000\n","16/16 [==============================] - 2s 107ms/step - loss: 0.8538 - R2: 0.7315 - val_loss: 1.0914 - val_R2: 0.6491\n","Epoch 195/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 0.8804 - R2: 0.7160 - val_loss: 1.0491 - val_R2: 0.6506\n","Epoch 196/2000\n","16/16 [==============================] - 2s 108ms/step - loss: 0.7988 - R2: 0.7531 - val_loss: 1.1192 - val_R2: 0.6443\n","Epoch 197/2000\n","16/16 [==============================] - 2s 105ms/step - loss: 0.7918 - R2: 0.7450 - val_loss: 1.1134 - val_R2: 0.6336\n","Epoch 198/2000\n","16/16 [==============================] - 2s 109ms/step - loss: 0.8379 - R2: 0.7348 - val_loss: 1.3299 - val_R2: 0.5701\n","Epoch 199/2000\n","16/16 [==============================] - 2s 112ms/step - loss: 0.8075 - R2: 0.7307 - val_loss: 1.1162 - val_R2: 0.6233\n","Epoch 00199: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f295c215310>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"DM2BdgFCE_JF"},"source":["generatorTest = SmilesGenerator(mols_test,y_test,sm_test, batch_size=X_test.shape[0], shuffle=True)\n","test_x, test_y = generatorTest.next()\n","y_pred  = model.predict(test_x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFTXPA0CGkHF","executionInfo":{"status":"ok","timestamp":1628609322828,"user_tz":180,"elapsed":693,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"da54f5b1-bff7-4de6-956d-bf0dac6b1dcf"},"source":["y_pred.reshape(-1).shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1021,)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"gK6arfjV-_8W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628609339205,"user_tz":180,"elapsed":502,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"8fe07253-0a4c-43e5-9aa6-1620cfb9d672"},"source":["R2_numpy(test_y, y_pred.reshape(-1))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6505620641463796"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"fkHZvdyxKbrV"},"source":["## **PRUEBA-2** Smiles Vectorizados - Bidirectional-LSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvMWNIs1Bm-B","executionInfo":{"status":"ok","timestamp":1628611661887,"user_tz":180,"elapsed":1175,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"3570e081-55be-4690-f924-6b6ed86d98d5"},"source":["# Modelo\n","#input_shape = X_testG.shape[1:]\n","model2 = Sequential()\n","model2.add(InputLayer(input_shape=input_shape))\n","model2.add(Bidirectional( LSTM(cant_neuronas_lstm,               \n","               dropout = lstm_dropout               \n","              )))\n","model2.add(Dense(cant_neuronas_hidden_layer))\n","model2.add(BatchNormalization())\n","model2.add( Activation('relu'))\n","\n","model2.add(Dense(output_shape,\n","                kernel_regularizer=regularizers.l1_l2(0.005,0.01),\n","                activation=\"linear\"))\n","\n","model2.compile(loss=\"mse\", optimizer=RMSprop(learning_rate=learning_rate),  metrics=[R2])\n","model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_4 (Bidirection (None, 128)               54272     \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 100)               12900     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 1)                 101       \n","=================================================================\n","Total params: 67,673\n","Trainable params: 67,473\n","Non-trainable params: 200\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AuXi3_k4Ln9m","outputId":"f67ebaf0-b51c-4140-f4f3-dd69bf53a25b"},"source":["#model2.fit(X_trainG, y_trainG, validation_data=(X_testG, y_testG), epochs=2000, batch_size=250, callbacks=[earlystop] )\n","model2.fit(generator, validation_data=generatorTest, steps_per_epoch=train_step, validation_steps=validation_step , epochs=2000, callbacks=[earlystop] )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2000\n","16/16 [==============================] - 8s 268ms/step - loss: 13.1042 - R2: -3.6627 - val_loss: 22.5565 - val_R2: -6.7814\n","Epoch 2/2000\n","16/16 [==============================] - 3s 194ms/step - loss: 3.7288 - R2: -0.2955 - val_loss: 18.7982 - val_R2: -5.4771\n","Epoch 3/2000\n","16/16 [==============================] - 3s 163ms/step - loss: 3.1738 - R2: -0.0998 - val_loss: 14.6009 - val_R2: -4.0236\n","Epoch 4/2000\n","16/16 [==============================] - 3s 194ms/step - loss: 2.6206 - R2: 0.0392 - val_loss: 14.2431 - val_R2: -3.9008\n","Epoch 5/2000\n","16/16 [==============================] - 3s 173ms/step - loss: 2.6312 - R2: 0.0907 - val_loss: 11.1288 - val_R2: -2.8242\n","Epoch 6/2000\n","16/16 [==============================] - 3s 174ms/step - loss: 2.6119 - R2: 0.1099 - val_loss: 12.7013 - val_R2: -3.3707\n","Epoch 7/2000\n","16/16 [==============================] - 3s 171ms/step - loss: 2.4660 - R2: 0.1244 - val_loss: 14.9311 - val_R2: -4.1445\n","Epoch 8/2000\n","16/16 [==============================] - 3s 167ms/step - loss: 2.5446 - R2: 0.1005 - val_loss: 14.9951 - val_R2: -4.1683\n","Epoch 9/2000\n","16/16 [==============================] - 3s 170ms/step - loss: 2.3234 - R2: 0.1562 - val_loss: 10.4448 - val_R2: -2.5926\n","Epoch 10/2000\n","16/16 [==============================] - 3s 190ms/step - loss: 2.2705 - R2: 0.1901 - val_loss: 9.7885 - val_R2: -2.3652\n","Epoch 11/2000\n","16/16 [==============================] - 3s 165ms/step - loss: 2.3227 - R2: 0.2127 - val_loss: 10.9509 - val_R2: -2.7691\n","Epoch 12/2000\n","16/16 [==============================] - 3s 190ms/step - loss: 2.0718 - R2: 0.2650 - val_loss: 8.7962 - val_R2: -2.0225\n","Epoch 13/2000\n","16/16 [==============================] - 3s 175ms/step - loss: 2.1568 - R2: 0.2533 - val_loss: 10.1040 - val_R2: -2.4763\n","Epoch 14/2000\n","16/16 [==============================] - 3s 177ms/step - loss: 1.9854 - R2: 0.2903 - val_loss: 8.0894 - val_R2: -1.7787\n","Epoch 15/2000\n","16/16 [==============================] - 3s 193ms/step - loss: 2.0998 - R2: 0.2824 - val_loss: 7.3632 - val_R2: -1.5272\n","Epoch 16/2000\n","16/16 [==============================] - 3s 192ms/step - loss: 1.9881 - R2: 0.2950 - val_loss: 5.3994 - val_R2: -0.8475\n","Epoch 17/2000\n","16/16 [==============================] - 3s 190ms/step - loss: 1.9889 - R2: 0.3245 - val_loss: 3.5303 - val_R2: -0.2000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ym391Fw8Mu1j"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oef3iJiqS7u9"},"source":["## **PRUEBA-3** Smiles Vectorizados - CNN tipo Inception\n","\n","-Mejor R2 de Validacion logrado= 0.65"]},{"cell_type":"code","metadata":{"id":"FgZZnOgZS9df"},"source":["# Implementar modelo de TextCNN\n","def text_cnn_1d_sinEmbedding(sequence_length, filter_sizes, num_filters):\n","    # Recordar que estamos en la funcional model API y hay que entender que conectar con que.\n","    input_x = Input(shape=sequence_length, name='input_x')\n","    #embedding_layer = Embedding(vocab_size+1, embedding_size, input_length=max_sequence_len)(input_x)\n","    pooled_outputs = []\n","    for filter_size in filter_sizes:\n","        conv1D = Conv1D( num_filters, filter_size, activation='relu', padding='same')(input_x)\n","        max_p = MaxPool1D()(conv1D)\n","        pooled_outputs.append(max_p)\n","\n","    #h_pool = Concatenate()(pooled_outputs)    \n","    h_pool = Concatenate(axis=2)(pooled_outputs)\n","    h_pool = GlobalMaxPooling1D()(h_pool)  #Flatten porque tengo MaxPool1D en vez de GlobalMaxPooling1D?\n","    dense = Dense(cant_neuronas_hidden_layer, activation='relu')(h_pool)\n","    dense=Dropout(0.2)(dense)\n","    dense = Dense(cant_neuronas_hidden_layer-50, activation='relu')(dense)\n","    dense=Dropout(0.2)(dense)\n","    dense = Dense(1)(dense) # Salida\n","    model = Model(input_x, dense)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-JRUd-IW3RY","executionInfo":{"status":"ok","timestamp":1628619841176,"user_tz":180,"elapsed":377,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"b9822668-e428-48d5-87a4-2ddaca931cbd"},"source":["model3 = text_cnn_1d_sinEmbedding(input_shape, FILTER_SIZES, NUM_FILTERS)\n","model3.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_x (InputLayer)            [(None, 217, 41)]    0                                            \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 217, 64)      7936        input_x[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 217, 64)      10560       input_x[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 217, 64)      13184       input_x[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling1d_3 (MaxPooling1D)  (None, 108, 64)      0           conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling1d_4 (MaxPooling1D)  (None, 108, 64)      0           conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling1d_5 (MaxPooling1D)  (None, 108, 64)      0           conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 108, 192)     0           max_pooling1d_3[0][0]            \n","                                                                 max_pooling1d_4[0][0]            \n","                                                                 max_pooling1d_5[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 192)          0           concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 100)          19300       global_max_pooling1d_1[0][0]     \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 100)          0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 50)           5050        dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 50)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1)            51          dropout_3[0][0]                  \n","==================================================================================================\n","Total params: 56,081\n","Trainable params: 56,081\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6Hp3vxg0XP6E"},"source":["model3.compile(loss=\"mse\", optimizer=RMSprop(learning_rate=learning_rate),  metrics=[R2])\n","#model3.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=[R2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5GsUVPoX_o0","executionInfo":{"status":"ok","timestamp":1628621277180,"user_tz":180,"elapsed":163514,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"5d87f459-178c-4ae5-e6e2-92ffda68d602"},"source":["#model3.fit(X_trainG, y_trainG, validation_data=(X_testG, y_testG), epochs=2000, batch_size=128, callbacks=[earlystop, tensorboard_callback] )\n","\n","model3.fit(generator, validation_data=generatorTest, steps_per_epoch=train_step, validation_steps=validation_step , epochs=2000, callbacks=[earlystop] )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2000\n","16/16 [==============================] - 5s 344ms/step - loss: 0.5852 - R2: 0.7955 - val_loss: 1.0701 - val_R2: 0.6151\n","Epoch 2/2000\n","16/16 [==============================] - 5s 340ms/step - loss: 0.6843 - R2: 0.7434 - val_loss: 1.1169 - val_R2: 0.6157\n","Epoch 3/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.6892 - R2: 0.7526 - val_loss: 0.9750 - val_R2: 0.6562\n","Epoch 4/2000\n","16/16 [==============================] - 6s 361ms/step - loss: 0.6762 - R2: 0.7531 - val_loss: 1.0430 - val_R2: 0.6346\n","Epoch 5/2000\n","16/16 [==============================] - 6s 361ms/step - loss: 0.6356 - R2: 0.7743 - val_loss: 1.2948 - val_R2: 0.5442\n","Epoch 6/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.6530 - R2: 0.7635 - val_loss: 0.9667 - val_R2: 0.6543\n","Epoch 7/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.6429 - R2: 0.7659 - val_loss: 0.9165 - val_R2: 0.6737\n","Epoch 8/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.6286 - R2: 0.7682 - val_loss: 0.9096 - val_R2: 0.6859\n","Epoch 9/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.5774 - R2: 0.7810 - val_loss: 0.9304 - val_R2: 0.6811\n","Epoch 10/2000\n","16/16 [==============================] - 5s 343ms/step - loss: 0.6092 - R2: 0.7734 - val_loss: 0.9059 - val_R2: 0.6796\n","Epoch 11/2000\n","16/16 [==============================] - 5s 345ms/step - loss: 0.6997 - R2: 0.7506 - val_loss: 0.9220 - val_R2: 0.6795\n","Epoch 12/2000\n","16/16 [==============================] - 5s 345ms/step - loss: 0.5737 - R2: 0.7853 - val_loss: 1.1515 - val_R2: 0.5934\n","Epoch 13/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.6544 - R2: 0.7605 - val_loss: 0.9482 - val_R2: 0.6687\n","Epoch 14/2000\n","16/16 [==============================] - 6s 345ms/step - loss: 0.5495 - R2: 0.7968 - val_loss: 0.8995 - val_R2: 0.6784\n","Epoch 15/2000\n","16/16 [==============================] - 6s 345ms/step - loss: 0.6873 - R2: 0.7720 - val_loss: 1.0137 - val_R2: 0.6451\n","Epoch 16/2000\n","16/16 [==============================] - 6s 346ms/step - loss: 0.6119 - R2: 0.7782 - val_loss: 1.2084 - val_R2: 0.5869\n","Epoch 17/2000\n","16/16 [==============================] - 6s 346ms/step - loss: 0.5772 - R2: 0.7899 - val_loss: 0.9773 - val_R2: 0.6630\n","Epoch 18/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.6075 - R2: 0.7762 - val_loss: 0.8221 - val_R2: 0.6830\n","Epoch 19/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.5924 - R2: 0.7851 - val_loss: 1.0518 - val_R2: 0.6331\n","Epoch 20/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.5906 - R2: 0.7865 - val_loss: 0.9549 - val_R2: 0.6636\n","Epoch 21/2000\n","16/16 [==============================] - 6s 365ms/step - loss: 0.5832 - R2: 0.7895 - val_loss: 1.4969 - val_R2: 0.4577\n","Epoch 22/2000\n","16/16 [==============================] - 6s 359ms/step - loss: 0.5971 - R2: 0.7791 - val_loss: 0.9237 - val_R2: 0.6761\n","Epoch 23/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.6314 - R2: 0.7762 - val_loss: 0.9720 - val_R2: 0.6578\n","Epoch 24/2000\n","16/16 [==============================] - 6s 350ms/step - loss: 0.6008 - R2: 0.7857 - val_loss: 1.0020 - val_R2: 0.6495\n","Epoch 25/2000\n","16/16 [==============================] - 6s 354ms/step - loss: 0.5914 - R2: 0.7889 - val_loss: 1.1633 - val_R2: 0.5840\n","Epoch 26/2000\n","16/16 [==============================] - 6s 350ms/step - loss: 0.5739 - R2: 0.7962 - val_loss: 0.9992 - val_R2: 0.6553\n","Epoch 27/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.5749 - R2: 0.7890 - val_loss: 0.9166 - val_R2: 0.6859\n","Epoch 28/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.5934 - R2: 0.7892 - val_loss: 0.8631 - val_R2: 0.7034\n","Epoch 29/2000\n","16/16 [==============================] - 6s 345ms/step - loss: 0.5477 - R2: 0.7970 - val_loss: 0.9522 - val_R2: 0.6713\n","Epoch 30/2000\n","16/16 [==============================] - 5s 343ms/step - loss: 0.5793 - R2: 0.7861 - val_loss: 0.9816 - val_R2: 0.6551\n","Epoch 31/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.5394 - R2: 0.7955 - val_loss: 1.2068 - val_R2: 0.5689\n","Epoch 32/2000\n","16/16 [==============================] - 5s 343ms/step - loss: 0.5789 - R2: 0.7967 - val_loss: 0.9658 - val_R2: 0.6642\n","Epoch 33/2000\n","16/16 [==============================] - 5s 343ms/step - loss: 0.5861 - R2: 0.7904 - val_loss: 0.9371 - val_R2: 0.6712\n","Epoch 34/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.5164 - R2: 0.8060 - val_loss: 0.8734 - val_R2: 0.6996\n","Epoch 35/2000\n","16/16 [==============================] - 6s 346ms/step - loss: 0.5490 - R2: 0.8043 - val_loss: 0.9029 - val_R2: 0.6848\n","Epoch 36/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.5280 - R2: 0.8047 - val_loss: 1.2025 - val_R2: 0.5821\n","Epoch 37/2000\n","16/16 [==============================] - 6s 354ms/step - loss: 0.5494 - R2: 0.8046 - val_loss: 0.9939 - val_R2: 0.6560\n","Epoch 38/2000\n","16/16 [==============================] - 6s 365ms/step - loss: 0.6214 - R2: 0.7832 - val_loss: 0.9299 - val_R2: 0.6747\n","Epoch 39/2000\n","16/16 [==============================] - 6s 363ms/step - loss: 0.5638 - R2: 0.7988 - val_loss: 1.0108 - val_R2: 0.6325\n","Epoch 40/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.5202 - R2: 0.8104 - val_loss: 1.2872 - val_R2: 0.5495\n","Epoch 41/2000\n","16/16 [==============================] - 6s 346ms/step - loss: 0.4973 - R2: 0.8187 - val_loss: 0.9686 - val_R2: 0.6606\n","Epoch 42/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.5585 - R2: 0.7774 - val_loss: 0.9398 - val_R2: 0.6682\n","Epoch 43/2000\n","16/16 [==============================] - 5s 344ms/step - loss: 0.5529 - R2: 0.7993 - val_loss: 0.9257 - val_R2: 0.6816\n","Epoch 44/2000\n","16/16 [==============================] - 6s 346ms/step - loss: 0.5494 - R2: 0.7970 - val_loss: 0.9769 - val_R2: 0.6577\n","Epoch 45/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.4459 - R2: 0.8347 - val_loss: 0.8874 - val_R2: 0.6958\n","Epoch 46/2000\n","16/16 [==============================] - 5s 345ms/step - loss: 0.5214 - R2: 0.8152 - val_loss: 0.9185 - val_R2: 0.6834\n","Epoch 47/2000\n","16/16 [==============================] - 5s 344ms/step - loss: 0.5222 - R2: 0.8030 - val_loss: 0.9409 - val_R2: 0.6766\n","Epoch 48/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.5562 - R2: 0.7812 - val_loss: 0.9041 - val_R2: 0.6844\n","Epoch 49/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.4580 - R2: 0.8412 - val_loss: 0.9527 - val_R2: 0.6682\n","Epoch 50/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.5369 - R2: 0.7907 - val_loss: 0.9093 - val_R2: 0.6821\n","Epoch 51/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.5337 - R2: 0.8220 - val_loss: 0.9486 - val_R2: 0.6748\n","Epoch 52/2000\n","16/16 [==============================] - 6s 354ms/step - loss: 0.4838 - R2: 0.8234 - val_loss: 0.9291 - val_R2: 0.6848\n","Epoch 53/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.5335 - R2: 0.8083 - val_loss: 0.9843 - val_R2: 0.6495\n","Epoch 54/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.5043 - R2: 0.8256 - val_loss: 0.8827 - val_R2: 0.6956\n","Epoch 55/2000\n","16/16 [==============================] - 6s 364ms/step - loss: 0.5206 - R2: 0.8123 - val_loss: 0.9905 - val_R2: 0.6461\n","Epoch 56/2000\n","16/16 [==============================] - 6s 366ms/step - loss: 0.4935 - R2: 0.8237 - val_loss: 0.8872 - val_R2: 0.6919\n","Epoch 57/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.5176 - R2: 0.8161 - val_loss: 0.9818 - val_R2: 0.6623\n","Epoch 58/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.4582 - R2: 0.8241 - val_loss: 0.8801 - val_R2: 0.6924\n","Epoch 59/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.5084 - R2: 0.8188 - val_loss: 1.0664 - val_R2: 0.6304\n","Epoch 60/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.5401 - R2: 0.8095 - val_loss: 1.1862 - val_R2: 0.5847\n","Epoch 61/2000\n","16/16 [==============================] - 6s 356ms/step - loss: 0.4946 - R2: 0.8192 - val_loss: 0.9693 - val_R2: 0.6710\n","Epoch 62/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.5005 - R2: 0.8204 - val_loss: 0.9485 - val_R2: 0.6665\n","Epoch 63/2000\n","16/16 [==============================] - 6s 354ms/step - loss: 0.4566 - R2: 0.8357 - val_loss: 0.8759 - val_R2: 0.6985\n","Epoch 64/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.5131 - R2: 0.8151 - val_loss: 1.0023 - val_R2: 0.6486\n","Epoch 65/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.4995 - R2: 0.8207 - val_loss: 0.9931 - val_R2: 0.6523\n","Epoch 66/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.5075 - R2: 0.8166 - val_loss: 0.9093 - val_R2: 0.6802\n","Epoch 67/2000\n","16/16 [==============================] - 6s 355ms/step - loss: 0.5312 - R2: 0.8073 - val_loss: 1.0027 - val_R2: 0.6527\n","Epoch 68/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.4315 - R2: 0.8398 - val_loss: 0.9618 - val_R2: 0.6702\n","Epoch 69/2000\n","16/16 [==============================] - 6s 355ms/step - loss: 0.4861 - R2: 0.8312 - val_loss: 1.0406 - val_R2: 0.6413\n","Epoch 70/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.4938 - R2: 0.8161 - val_loss: 0.8946 - val_R2: 0.6795\n","Epoch 71/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.4867 - R2: 0.8204 - val_loss: 0.9805 - val_R2: 0.6429\n","Epoch 72/2000\n","16/16 [==============================] - 6s 362ms/step - loss: 0.4891 - R2: 0.8249 - val_loss: 0.9876 - val_R2: 0.6549\n","Epoch 73/2000\n","16/16 [==============================] - 6s 357ms/step - loss: 0.4617 - R2: 0.8326 - val_loss: 1.2615 - val_R2: 0.5483\n","Epoch 74/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.4934 - R2: 0.8205 - val_loss: 1.0361 - val_R2: 0.6415\n","Epoch 75/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.4414 - R2: 0.8353 - val_loss: 0.9246 - val_R2: 0.6812\n","Epoch 76/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.5017 - R2: 0.8245 - val_loss: 0.9309 - val_R2: 0.6611\n","Epoch 77/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.4457 - R2: 0.8312 - val_loss: 1.0131 - val_R2: 0.6543\n","Epoch 78/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.4700 - R2: 0.8283 - val_loss: 1.1175 - val_R2: 0.6083\n","Epoch 79/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.4635 - R2: 0.8258 - val_loss: 0.9576 - val_R2: 0.6627\n","Epoch 80/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.4905 - R2: 0.8374 - val_loss: 0.9527 - val_R2: 0.6586\n","Epoch 81/2000\n","16/16 [==============================] - 6s 359ms/step - loss: 0.4494 - R2: 0.8365 - val_loss: 1.0937 - val_R2: 0.6198\n","Epoch 82/2000\n","16/16 [==============================] - 6s 354ms/step - loss: 0.4868 - R2: 0.8089 - val_loss: 0.9728 - val_R2: 0.6501\n","Epoch 83/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.4767 - R2: 0.8311 - val_loss: 0.9859 - val_R2: 0.6553\n","Epoch 84/2000\n","16/16 [==============================] - 6s 348ms/step - loss: 0.4294 - R2: 0.8468 - val_loss: 0.9157 - val_R2: 0.6783\n","Epoch 85/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.4920 - R2: 0.8154 - val_loss: 0.8991 - val_R2: 0.6895\n","Epoch 86/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.4406 - R2: 0.8441 - val_loss: 0.9539 - val_R2: 0.6598\n","Epoch 87/2000\n","16/16 [==============================] - 5s 344ms/step - loss: 0.4431 - R2: 0.8398 - val_loss: 0.9288 - val_R2: 0.6779\n","Epoch 88/2000\n","16/16 [==============================] - 6s 346ms/step - loss: 0.4806 - R2: 0.8307 - val_loss: 0.9259 - val_R2: 0.6740\n","Epoch 89/2000\n","16/16 [==============================] - 6s 360ms/step - loss: 0.4524 - R2: 0.8375 - val_loss: 0.9801 - val_R2: 0.6472\n","Epoch 90/2000\n","16/16 [==============================] - 6s 364ms/step - loss: 0.4536 - R2: 0.8352 - val_loss: 0.9703 - val_R2: 0.6648\n","Epoch 91/2000\n","16/16 [==============================] - 6s 357ms/step - loss: 0.4348 - R2: 0.8412 - val_loss: 0.8741 - val_R2: 0.6928\n","Epoch 92/2000\n","16/16 [==============================] - 6s 357ms/step - loss: 0.4516 - R2: 0.8361 - val_loss: 1.1876 - val_R2: 0.5896\n","Epoch 93/2000\n","16/16 [==============================] - 6s 355ms/step - loss: 0.4225 - R2: 0.8427 - val_loss: 1.2679 - val_R2: 0.5386\n","Epoch 94/2000\n","16/16 [==============================] - 6s 356ms/step - loss: 0.4748 - R2: 0.8347 - val_loss: 0.8980 - val_R2: 0.6900\n","Epoch 95/2000\n","16/16 [==============================] - 6s 356ms/step - loss: 0.4082 - R2: 0.8445 - val_loss: 0.8865 - val_R2: 0.6860\n","Epoch 96/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.4554 - R2: 0.8470 - val_loss: 0.9155 - val_R2: 0.6739\n","Epoch 97/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.4594 - R2: 0.8219 - val_loss: 0.9740 - val_R2: 0.6611\n","Epoch 98/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.4076 - R2: 0.8519 - val_loss: 0.9391 - val_R2: 0.6611\n","Epoch 99/2000\n","16/16 [==============================] - 6s 350ms/step - loss: 0.4387 - R2: 0.8304 - val_loss: 0.8845 - val_R2: 0.6939\n","Epoch 100/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.4377 - R2: 0.8422 - val_loss: 0.9295 - val_R2: 0.6786\n","Epoch 101/2000\n","16/16 [==============================] - 6s 355ms/step - loss: 0.3767 - R2: 0.8645 - val_loss: 0.9415 - val_R2: 0.6641\n","Epoch 102/2000\n","16/16 [==============================] - 6s 355ms/step - loss: 0.5014 - R2: 0.8180 - val_loss: 0.9058 - val_R2: 0.6837\n","Epoch 103/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.4520 - R2: 0.8417 - val_loss: 0.8641 - val_R2: 0.6892\n","Epoch 104/2000\n","16/16 [==============================] - 6s 354ms/step - loss: 0.3709 - R2: 0.8626 - val_loss: 0.8928 - val_R2: 0.6926\n","Epoch 105/2000\n","16/16 [==============================] - 6s 355ms/step - loss: 0.4309 - R2: 0.8483 - val_loss: 0.8988 - val_R2: 0.6896\n","Epoch 106/2000\n","16/16 [==============================] - 6s 369ms/step - loss: 0.4305 - R2: 0.8422 - val_loss: 0.9248 - val_R2: 0.6812\n","Epoch 107/2000\n","16/16 [==============================] - 6s 371ms/step - loss: 0.4174 - R2: 0.8484 - val_loss: 0.8795 - val_R2: 0.6969\n","Epoch 108/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.4367 - R2: 0.8395 - val_loss: 0.8262 - val_R2: 0.6932\n","Epoch 109/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.4129 - R2: 0.8486 - val_loss: 0.8605 - val_R2: 0.7066\n","Epoch 110/2000\n","16/16 [==============================] - 6s 355ms/step - loss: 0.4136 - R2: 0.8572 - val_loss: 1.0411 - val_R2: 0.6383\n","Epoch 111/2000\n","16/16 [==============================] - 6s 354ms/step - loss: 0.4163 - R2: 0.8405 - val_loss: 0.8440 - val_R2: 0.7042\n","Epoch 112/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.3969 - R2: 0.8593 - val_loss: 0.8716 - val_R2: 0.6891\n","Epoch 113/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.4384 - R2: 0.8387 - val_loss: 0.8697 - val_R2: 0.6842\n","Epoch 114/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.3946 - R2: 0.8565 - val_loss: 0.8952 - val_R2: 0.6851\n","Epoch 115/2000\n","16/16 [==============================] - 6s 351ms/step - loss: 0.4052 - R2: 0.8532 - val_loss: 0.8775 - val_R2: 0.6965\n","Epoch 116/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.4438 - R2: 0.8364 - val_loss: 0.8680 - val_R2: 0.6927\n","Epoch 117/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.3752 - R2: 0.8539 - val_loss: 0.8371 - val_R2: 0.6967\n","Epoch 118/2000\n","16/16 [==============================] - 6s 349ms/step - loss: 0.4018 - R2: 0.8574 - val_loss: 0.9057 - val_R2: 0.6720\n","Epoch 119/2000\n","16/16 [==============================] - 6s 347ms/step - loss: 0.4256 - R2: 0.8461 - val_loss: 0.9344 - val_R2: 0.6773\n","Epoch 120/2000\n","16/16 [==============================] - 6s 353ms/step - loss: 0.4338 - R2: 0.8426 - val_loss: 0.9163 - val_R2: 0.6892\n","Epoch 121/2000\n","16/16 [==============================] - 6s 352ms/step - loss: 0.3904 - R2: 0.8544 - val_loss: 1.0127 - val_R2: 0.6509\n","Epoch 00121: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff0fc48b410>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CYs6SdapAEZV","executionInfo":{"status":"ok","timestamp":1628564389783,"user_tz":180,"elapsed":349,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"3d58e95d-0f51-4dc8-a49d-848ceb478f9e"},"source":["path+'fit_tensorboard/'\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/TRABAJO/Data Science/ITBA-DeepLearning/Notebooks/TP-FINAL/bioinformatics_final_project/fit_tensorboard/'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"LtulU4voBwjv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4d6X3HZYLYz"},"source":["%load_ext tensorboard\n","%tensorboard --logdir log_dir=path+'fit_tensorboard/*'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWpvf4gS_8HR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xtKhO0TwYxcQ"},"source":["# Utilizando de Input a Fingerprints"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XlqtDwYU3lCs","executionInfo":{"status":"ok","timestamp":1628696393642,"user_tz":180,"elapsed":3653,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"4fcca804-4ad5-41b6-e4c5-165676477cc6"},"source":["!pip install pandas_summary\n","from pandas_summary import DataFrameSummary\n","from sklearn.preprocessing import LabelEncoder, StandardScaler"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pandas_summary\n","  Downloading pandas_summary-0.0.7-py2.py3-none-any.whl (5.2 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandas_summary) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas_summary) (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_summary) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas_summary) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandas_summary) (1.15.0)\n","Installing collected packages: pandas-summary\n","Successfully installed pandas-summary-0.0.7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gz2hMG3ooNiT"},"source":["## Carga de Datos"]},{"cell_type":"code","metadata":{"id":"TZ9xjIHwZDPJ"},"source":["df_completo = pd.read_csv(path+'data/acetylcholinesterase_02_bioactivity_data_preprocessed_token_descriptors.csv')\n","X= df_completo.drop(['molecule_chembl_id', 'canonical_smiles', 'standard_value',\n","       'standard_value_norm', 'pIC50', 'X_seq', 'X_seq_pad', 'MW', 'LogP',\n","       'NumHDonors', 'NumHAcceptors', 'bioactivity_class', 'Name'], axis=1)\n","y = df_completo.pIC50.values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NKJZ7lxl_Zoc"},"source":["Los features de fingerprints son booleanos, lo normalizamos aunque tambien se puede utilizarlos como vienen"]},{"cell_type":"code","metadata":{"id":"cAx3COER-y7Y"},"source":["normalizar_features = False\n","if normalizar_features:\n","  from sklearn_pandas import DataFrameMapper\n","  contin_maps = [([o], StandardScaler()) for o in X.columns.values]\n","  mapper_cont = DataFrameMapper(contin_maps)\n","  X[X.columns.values] = mapper_cont.fit_transform(X)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXrqQy9y4Ieo","executionInfo":{"status":"ok","timestamp":1628704319343,"user_tz":180,"elapsed":10920,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"911e364d-f176-419c-fa9e-fc0eee89e6d8"},"source":["summary = DataFrameSummary(X).summary().loc[['uniques', 'types', 'missing']]\n","summary"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PubchemFP0</th>\n","      <th>PubchemFP1</th>\n","      <th>PubchemFP2</th>\n","      <th>PubchemFP3</th>\n","      <th>PubchemFP4</th>\n","      <th>PubchemFP5</th>\n","      <th>PubchemFP6</th>\n","      <th>PubchemFP7</th>\n","      <th>PubchemFP8</th>\n","      <th>PubchemFP9</th>\n","      <th>PubchemFP10</th>\n","      <th>PubchemFP11</th>\n","      <th>PubchemFP12</th>\n","      <th>PubchemFP13</th>\n","      <th>PubchemFP14</th>\n","      <th>PubchemFP15</th>\n","      <th>PubchemFP16</th>\n","      <th>PubchemFP17</th>\n","      <th>PubchemFP18</th>\n","      <th>PubchemFP19</th>\n","      <th>PubchemFP20</th>\n","      <th>PubchemFP21</th>\n","      <th>PubchemFP22</th>\n","      <th>PubchemFP23</th>\n","      <th>PubchemFP24</th>\n","      <th>PubchemFP25</th>\n","      <th>PubchemFP26</th>\n","      <th>PubchemFP27</th>\n","      <th>PubchemFP28</th>\n","      <th>PubchemFP29</th>\n","      <th>PubchemFP30</th>\n","      <th>PubchemFP31</th>\n","      <th>PubchemFP32</th>\n","      <th>PubchemFP33</th>\n","      <th>PubchemFP34</th>\n","      <th>PubchemFP35</th>\n","      <th>PubchemFP36</th>\n","      <th>PubchemFP37</th>\n","      <th>PubchemFP38</th>\n","      <th>PubchemFP39</th>\n","      <th>...</th>\n","      <th>PubchemFP841</th>\n","      <th>PubchemFP842</th>\n","      <th>PubchemFP843</th>\n","      <th>PubchemFP844</th>\n","      <th>PubchemFP845</th>\n","      <th>PubchemFP846</th>\n","      <th>PubchemFP847</th>\n","      <th>PubchemFP848</th>\n","      <th>PubchemFP849</th>\n","      <th>PubchemFP850</th>\n","      <th>PubchemFP851</th>\n","      <th>PubchemFP852</th>\n","      <th>PubchemFP853</th>\n","      <th>PubchemFP854</th>\n","      <th>PubchemFP855</th>\n","      <th>PubchemFP856</th>\n","      <th>PubchemFP857</th>\n","      <th>PubchemFP858</th>\n","      <th>PubchemFP859</th>\n","      <th>PubchemFP860</th>\n","      <th>PubchemFP861</th>\n","      <th>PubchemFP862</th>\n","      <th>PubchemFP863</th>\n","      <th>PubchemFP864</th>\n","      <th>PubchemFP865</th>\n","      <th>PubchemFP866</th>\n","      <th>PubchemFP867</th>\n","      <th>PubchemFP868</th>\n","      <th>PubchemFP869</th>\n","      <th>PubchemFP870</th>\n","      <th>PubchemFP871</th>\n","      <th>PubchemFP872</th>\n","      <th>PubchemFP873</th>\n","      <th>PubchemFP874</th>\n","      <th>PubchemFP875</th>\n","      <th>PubchemFP876</th>\n","      <th>PubchemFP877</th>\n","      <th>PubchemFP878</th>\n","      <th>PubchemFP879</th>\n","      <th>PubchemFP880</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>uniques</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>types</th>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>...</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>bool</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","      <td>constant</td>\n","    </tr>\n","    <tr>\n","      <th>missing</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows  881 columns</p>\n","</div>"],"text/plain":["        PubchemFP0 PubchemFP1 PubchemFP2  ... PubchemFP878 PubchemFP879 PubchemFP880\n","uniques          2          2          2  ...            1            1            1\n","types         bool       bool       bool  ...     constant     constant     constant\n","missing          0          0          0  ...            0            0            0\n","\n","[3 rows x 881 columns]"]},"metadata":{"tags":[]},"execution_count":201}]},{"cell_type":"markdown","metadata":{"id":"-z73mWmK8hWe"},"source":["Tienen muchos features que siempre estan en cero, presentamos dos formas de depuraralos:\n","1. Solo nos quedamos con las que son binarias y presentan valores 0 o 1\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4yOtkWS6Y0C","executionInfo":{"status":"ok","timestamp":1628704327496,"user_tz":180,"elapsed":230,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"afd95d06-b973-47c8-cf6f-8609cd356586"},"source":["b = summary.T\n","boolean = b[b.uniques==2]\n","colbool = boolean.T\n","X=X[colbool.columns.values]\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5103, 634)"]},"metadata":{"tags":[]},"execution_count":202}]},{"cell_type":"markdown","metadata":{"id":"dFlgveWI9iqj"},"source":["2. Otra opcin es quedarnos con las que tienen un varianza alta"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSG_Q0mY6EeH","executionInfo":{"status":"ok","timestamp":1628704330463,"user_tz":180,"elapsed":264,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"7554b603-a57a-4d50-ebf6-56f4656e2c16"},"source":["from sklearn.feature_selection import VarianceThreshold\n","selection = VarianceThreshold(threshold=(.8 * (1 - .8)))    \n","X_variance = selection.fit_transform(X)\n","print(X_variance.shape, X.shape) # Reduccion de 881 a 140 features (elimino 741 features de baja varianza)\n","X=X_variance"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(5103, 140) (5103, 634)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B1Eb1a-3oS_l"},"source":["## Split de Datos"]},{"cell_type":"code","metadata":{"id":"BAoxHYY2oWO5"},"source":["X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TIAjBLyypm5-"},"source":["## Hiper - Parametros "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8c3QfyQnqZpX","executionInfo":{"status":"ok","timestamp":1628704338353,"user_tz":180,"elapsed":206,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"994e3694-f736-4f57-eff3-4ec0091e756c"},"source":[" X.shape[1:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(140,)"]},"metadata":{"tags":[]},"execution_count":205}]},{"cell_type":"code","metadata":{"id":"NoBCNnQNprxA"},"source":["#Parametros - Hiper-parametros Generales\n","#x_temp, y_temp = generator.next()\n","batch_size = 250\n","input_shape = X.shape[1]\n","output_shape = 1\n","train_step = round(y_train.shape[0]/batch_size)\n","validation_step = round(y_val.shape[0]/batch_size)\n","lstm_dropout = 0.19\n","reg_l1 = 0.005\n","reg_l2 = 0.01\n","learning_rate=0.01\n","cant_neuronas_lstm = 64\n","cant_neuronas_hidden_layer = 100\n","\n","FILTER_SIZES = (3, 4, 5)\n","NUM_FILTERS = 64\n","\n","\n","first_hidden_units = 1000\n","second_hidden_units = 500\n","l2_lambda = 1e-3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUqMKdZjFIoT"},"source":["earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pze_0ol1pTIB"},"source":["### MLP con FingerPrints"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yQ-Upf4pSRM","executionInfo":{"status":"ok","timestamp":1628705328025,"user_tz":180,"elapsed":316,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"165cd88c-deb3-4516-e930-a0b35cf0e9d7"},"source":["# Modelo\n","model = Sequential()\n","model.add(Dense(25, input_shape=(input_shape,) ))\n","model.add(BatchNormalization())\n","model.add(Activation('linear'))\n","model.add(Dropout(0.2))\n","model.add(Dense(50))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(50))##, kernel_regularizer=l2(l2_lambda)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(output_shape,\n","                kernel_regularizer=regularizers.l1_l2(reg_l1,reg_l2),\n","                activation=\"linear\"))\n","\n","model.compile(loss=\"mse\", optimizer=RMSprop(learning_rate=learning_rate),  metrics=[R2])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_32\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_94 (Dense)             (None, 25)                3525      \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 25)                100       \n","_________________________________________________________________\n","activation_34 (Activation)   (None, 25)                0         \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 25)                0         \n","_________________________________________________________________\n","dense_95 (Dense)             (None, 50)                1300      \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 50)                200       \n","_________________________________________________________________\n","activation_35 (Activation)   (None, 50)                0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 50)                0         \n","_________________________________________________________________\n","dense_96 (Dense)             (None, 50)                2550      \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 50)                200       \n","_________________________________________________________________\n","activation_36 (Activation)   (None, 50)                0         \n","_________________________________________________________________\n","dropout_32 (Dropout)         (None, 50)                0         \n","_________________________________________________________________\n","dense_97 (Dense)             (None, 1)                 51        \n","=================================================================\n","Total params: 7,926\n","Trainable params: 7,676\n","Non-trainable params: 250\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_eEoBIDxCf_","executionInfo":{"status":"ok","timestamp":1628705368134,"user_tz":180,"elapsed":36282,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"28790e4c-050b-45eb-b7f6-997d940a5279"},"source":["model.compile(loss=\"mse\", optimizer=RMSprop(learning_rate=learning_rate),  metrics=[R2])\n","model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=2000, callbacks=[earlystop] )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2000\n","17/17 [==============================] - 2s 19ms/step - loss: 7.9884 - R2: -1.8041 - val_loss: 14.0260 - val_R2: -4.7029\n","Epoch 2/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 3.4483 - R2: -0.2198 - val_loss: 22.6698 - val_R2: -8.1498\n","Epoch 3/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 3.3130 - R2: -0.1640 - val_loss: 5.1045 - val_R2: -0.9472\n","Epoch 4/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 3.1934 - R2: -0.1380 - val_loss: 5.9272 - val_R2: -1.3514\n","Epoch 5/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 3.0412 - R2: -0.0721 - val_loss: 8.3366 - val_R2: -2.5002\n","Epoch 6/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.9698 - R2: -0.0450 - val_loss: 4.2617 - val_R2: -0.5833\n","Epoch 7/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.9339 - R2: -0.0351 - val_loss: 5.4106 - val_R2: -1.1898\n","Epoch 8/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.8414 - R2: 0.0029 - val_loss: 4.8532 - val_R2: -0.8329\n","Epoch 9/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.7455 - R2: 0.0302 - val_loss: 3.5835 - val_R2: -0.2860\n","Epoch 10/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.6774 - R2: 0.0627 - val_loss: 3.6444 - val_R2: -0.3325\n","Epoch 11/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.7528 - R2: 0.0275 - val_loss: 2.9887 - val_R2: -0.0810\n","Epoch 12/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.7094 - R2: 0.0399 - val_loss: 3.0784 - val_R2: -0.0337\n","Epoch 13/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.6205 - R2: 0.0579 - val_loss: 2.7346 - val_R2: 0.0128\n","Epoch 14/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.6508 - R2: 0.0632 - val_loss: 2.6168 - val_R2: 0.1387\n","Epoch 15/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.5282 - R2: 0.1019 - val_loss: 2.8909 - val_R2: -0.0172\n","Epoch 16/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.5610 - R2: 0.0806 - val_loss: 2.7760 - val_R2: -0.0330\n","Epoch 17/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.4739 - R2: 0.1279 - val_loss: 2.6582 - val_R2: 0.0550\n","Epoch 18/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.4574 - R2: 0.1330 - val_loss: 2.5698 - val_R2: 0.0783\n","Epoch 19/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.4646 - R2: 0.1257 - val_loss: 2.4684 - val_R2: 0.1367\n","Epoch 20/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.4955 - R2: 0.1128 - val_loss: 2.5125 - val_R2: 0.1070\n","Epoch 21/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.4160 - R2: 0.1398 - val_loss: 2.3848 - val_R2: 0.1145\n","Epoch 22/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.3577 - R2: 0.1668 - val_loss: 2.8165 - val_R2: 0.0467\n","Epoch 23/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.3836 - R2: 0.1564 - val_loss: 2.6409 - val_R2: 0.1060\n","Epoch 24/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.4160 - R2: 0.1513 - val_loss: 2.3848 - val_R2: 0.1911\n","Epoch 25/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.3066 - R2: 0.1904 - val_loss: 2.3791 - val_R2: 0.1778\n","Epoch 26/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.2922 - R2: 0.1841 - val_loss: 2.5175 - val_R2: 0.1709\n","Epoch 27/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.2665 - R2: 0.2073 - val_loss: 2.2485 - val_R2: 0.2259\n","Epoch 28/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.3226 - R2: 0.1733 - val_loss: 2.4068 - val_R2: 0.2221\n","Epoch 29/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.2961 - R2: 0.1931 - val_loss: 2.7711 - val_R2: -0.0157\n","Epoch 30/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.2514 - R2: 0.2138 - val_loss: 2.2216 - val_R2: 0.2382\n","Epoch 31/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.2712 - R2: 0.1984 - val_loss: 2.2707 - val_R2: 0.2253\n","Epoch 32/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.2185 - R2: 0.2128 - val_loss: 3.2974 - val_R2: -0.0813\n","Epoch 33/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.2562 - R2: 0.1971 - val_loss: 2.2406 - val_R2: 0.2447\n","Epoch 34/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1909 - R2: 0.2152 - val_loss: 2.2340 - val_R2: 0.2176\n","Epoch 35/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.2390 - R2: 0.2072 - val_loss: 2.4093 - val_R2: 0.2133\n","Epoch 36/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.2179 - R2: 0.2041 - val_loss: 2.2382 - val_R2: 0.2640\n","Epoch 37/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1689 - R2: 0.2303 - val_loss: 2.5298 - val_R2: 0.1967\n","Epoch 38/2000\n","17/17 [==============================] - 0s 5ms/step - loss: 2.2162 - R2: 0.2112 - val_loss: 2.2951 - val_R2: 0.1965\n","Epoch 39/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1794 - R2: 0.2246 - val_loss: 2.3101 - val_R2: 0.2007\n","Epoch 40/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1431 - R2: 0.2405 - val_loss: 2.2291 - val_R2: 0.2397\n","Epoch 41/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.1357 - R2: 0.2403 - val_loss: 2.3386 - val_R2: 0.2373\n","Epoch 42/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1554 - R2: 0.2367 - val_loss: 2.3911 - val_R2: 0.1862\n","Epoch 43/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1473 - R2: 0.2310 - val_loss: 2.1577 - val_R2: 0.2735\n","Epoch 44/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.1102 - R2: 0.2465 - val_loss: 2.4543 - val_R2: 0.2054\n","Epoch 45/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1189 - R2: 0.2453 - val_loss: 2.2055 - val_R2: 0.2440\n","Epoch 46/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1275 - R2: 0.2277 - val_loss: 2.4223 - val_R2: 0.1914\n","Epoch 47/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1090 - R2: 0.2436 - val_loss: 2.1717 - val_R2: 0.2800\n","Epoch 48/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.0803 - R2: 0.2628 - val_loss: 2.4013 - val_R2: 0.2141\n","Epoch 49/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1006 - R2: 0.2571 - val_loss: 2.4287 - val_R2: 0.1433\n","Epoch 50/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.0661 - R2: 0.2718 - val_loss: 2.1957 - val_R2: 0.2576\n","Epoch 51/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.1413 - R2: 0.2335 - val_loss: 2.2422 - val_R2: 0.2299\n","Epoch 52/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9996 - R2: 0.2852 - val_loss: 2.2503 - val_R2: 0.2483\n","Epoch 53/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.0648 - R2: 0.2591 - val_loss: 2.3872 - val_R2: 0.1876\n","Epoch 54/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.0478 - R2: 0.2786 - val_loss: 2.1923 - val_R2: 0.2829\n","Epoch 55/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.0396 - R2: 0.2775 - val_loss: 2.3214 - val_R2: 0.2460\n","Epoch 56/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.0636 - R2: 0.2668 - val_loss: 2.3649 - val_R2: 0.1466\n","Epoch 57/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.0464 - R2: 0.2691 - val_loss: 2.2059 - val_R2: 0.2477\n","Epoch 58/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.0357 - R2: 0.2769 - val_loss: 2.5142 - val_R2: 0.1016\n","Epoch 59/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.0365 - R2: 0.2665 - val_loss: 2.1212 - val_R2: 0.2692\n","Epoch 60/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9977 - R2: 0.2862 - val_loss: 2.1245 - val_R2: 0.2610\n","Epoch 61/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9903 - R2: 0.2914 - val_loss: 2.2908 - val_R2: 0.2491\n","Epoch 62/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 2.0159 - R2: 0.2792 - val_loss: 2.1733 - val_R2: 0.2357\n","Epoch 63/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9502 - R2: 0.3074 - val_loss: 2.3083 - val_R2: 0.2511\n","Epoch 64/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.0125 - R2: 0.2699 - val_loss: 2.1004 - val_R2: 0.2809\n","Epoch 65/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9435 - R2: 0.3039 - val_loss: 2.3034 - val_R2: 0.2302\n","Epoch 66/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 2.0024 - R2: 0.2847 - val_loss: 2.2504 - val_R2: 0.2471\n","Epoch 67/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9382 - R2: 0.2904 - val_loss: 2.4658 - val_R2: 0.1974\n","Epoch 68/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9192 - R2: 0.3129 - val_loss: 2.2463 - val_R2: 0.2732\n","Epoch 69/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9928 - R2: 0.2842 - val_loss: 2.1745 - val_R2: 0.2653\n","Epoch 70/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9707 - R2: 0.2980 - val_loss: 2.5749 - val_R2: 0.0857\n","Epoch 71/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9387 - R2: 0.3098 - val_loss: 2.1859 - val_R2: 0.2143\n","Epoch 72/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9108 - R2: 0.3170 - val_loss: 2.2827 - val_R2: 0.1697\n","Epoch 73/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9300 - R2: 0.3218 - val_loss: 2.5951 - val_R2: 0.1780\n","Epoch 74/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9056 - R2: 0.3251 - val_loss: 2.1201 - val_R2: 0.2774\n","Epoch 75/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9121 - R2: 0.3122 - val_loss: 2.2387 - val_R2: 0.2407\n","Epoch 76/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9693 - R2: 0.3087 - val_loss: 2.1876 - val_R2: 0.2874\n","Epoch 77/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9724 - R2: 0.2980 - val_loss: 2.1241 - val_R2: 0.3126\n","Epoch 78/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9181 - R2: 0.3221 - val_loss: 2.1468 - val_R2: 0.2885\n","Epoch 79/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.8800 - R2: 0.3364 - val_loss: 2.4789 - val_R2: 0.1971\n","Epoch 80/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9243 - R2: 0.3160 - val_loss: 2.3127 - val_R2: 0.2392\n","Epoch 81/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9246 - R2: 0.3140 - val_loss: 2.1108 - val_R2: 0.3119\n","Epoch 82/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8950 - R2: 0.3359 - val_loss: 2.5371 - val_R2: 0.1202\n","Epoch 83/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9096 - R2: 0.3271 - val_loss: 2.1365 - val_R2: 0.2852\n","Epoch 84/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8945 - R2: 0.3232 - val_loss: 2.5260 - val_R2: 0.1265\n","Epoch 85/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8876 - R2: 0.3268 - val_loss: 2.2262 - val_R2: 0.2776\n","Epoch 86/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9107 - R2: 0.3185 - val_loss: 2.0253 - val_R2: 0.3207\n","Epoch 87/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8954 - R2: 0.3228 - val_loss: 2.2799 - val_R2: 0.2050\n","Epoch 88/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9089 - R2: 0.3190 - val_loss: 2.2273 - val_R2: 0.2752\n","Epoch 89/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.9427 - R2: 0.3034 - val_loss: 2.1734 - val_R2: 0.2802\n","Epoch 90/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8555 - R2: 0.3443 - val_loss: 2.4294 - val_R2: 0.1949\n","Epoch 91/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8958 - R2: 0.3220 - val_loss: 2.0758 - val_R2: 0.2924\n","Epoch 92/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8309 - R2: 0.3499 - val_loss: 2.0818 - val_R2: 0.3001\n","Epoch 93/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8485 - R2: 0.3425 - val_loss: 2.1566 - val_R2: 0.2261\n","Epoch 94/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8486 - R2: 0.3427 - val_loss: 2.0488 - val_R2: 0.3014\n","Epoch 95/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8247 - R2: 0.3512 - val_loss: 2.1214 - val_R2: 0.2809\n","Epoch 96/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8210 - R2: 0.3509 - val_loss: 2.2996 - val_R2: 0.2544\n","Epoch 97/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.8597 - R2: 0.3470 - val_loss: 2.1455 - val_R2: 0.2614\n","Epoch 98/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8772 - R2: 0.3366 - val_loss: 2.5992 - val_R2: 0.0990\n","Epoch 99/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.9061 - R2: 0.3220 - val_loss: 2.0617 - val_R2: 0.2944\n","Epoch 100/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8516 - R2: 0.3422 - val_loss: 2.2256 - val_R2: 0.1831\n","Epoch 101/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.8227 - R2: 0.3596 - val_loss: 2.4281 - val_R2: 0.1315\n","Epoch 102/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8471 - R2: 0.3434 - val_loss: 2.1874 - val_R2: 0.2590\n","Epoch 103/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8345 - R2: 0.3547 - val_loss: 2.0685 - val_R2: 0.3042\n","Epoch 104/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8606 - R2: 0.3420 - val_loss: 2.1257 - val_R2: 0.2835\n","Epoch 105/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8816 - R2: 0.3276 - val_loss: 2.1244 - val_R2: 0.3056\n","Epoch 106/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8577 - R2: 0.3449 - val_loss: 2.3610 - val_R2: 0.2308\n","Epoch 107/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8305 - R2: 0.3473 - val_loss: 2.3038 - val_R2: 0.1861\n","Epoch 108/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8151 - R2: 0.3540 - val_loss: 2.1327 - val_R2: 0.2923\n","Epoch 109/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8064 - R2: 0.3499 - val_loss: 2.0886 - val_R2: 0.2855\n","Epoch 110/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8317 - R2: 0.3375 - val_loss: 2.1820 - val_R2: 0.2165\n","Epoch 111/2000\n","17/17 [==============================] - 0s 5ms/step - loss: 1.8134 - R2: 0.3528 - val_loss: 2.1231 - val_R2: 0.2583\n","Epoch 112/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7914 - R2: 0.3651 - val_loss: 2.0668 - val_R2: 0.2812\n","Epoch 113/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8261 - R2: 0.3515 - val_loss: 2.3786 - val_R2: 0.2393\n","Epoch 114/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8302 - R2: 0.3457 - val_loss: 2.2162 - val_R2: 0.2775\n","Epoch 115/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8048 - R2: 0.3623 - val_loss: 2.1479 - val_R2: 0.2419\n","Epoch 116/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8097 - R2: 0.3649 - val_loss: 2.1941 - val_R2: 0.2169\n","Epoch 117/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8000 - R2: 0.3573 - val_loss: 2.1518 - val_R2: 0.2820\n","Epoch 118/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7953 - R2: 0.3704 - val_loss: 2.1857 - val_R2: 0.2894\n","Epoch 119/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7989 - R2: 0.3602 - val_loss: 2.0952 - val_R2: 0.2996\n","Epoch 120/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7887 - R2: 0.3639 - val_loss: 2.1802 - val_R2: 0.2430\n","Epoch 121/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8251 - R2: 0.3466 - val_loss: 2.0788 - val_R2: 0.2839\n","Epoch 122/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8093 - R2: 0.3574 - val_loss: 2.2002 - val_R2: 0.2698\n","Epoch 123/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8033 - R2: 0.3583 - val_loss: 2.1965 - val_R2: 0.2701\n","Epoch 124/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7679 - R2: 0.3727 - val_loss: 2.2800 - val_R2: 0.2624\n","Epoch 125/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8022 - R2: 0.3632 - val_loss: 2.1102 - val_R2: 0.2979\n","Epoch 126/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7918 - R2: 0.3486 - val_loss: 2.0161 - val_R2: 0.3170\n","Epoch 127/2000\n","17/17 [==============================] - 0s 5ms/step - loss: 1.7866 - R2: 0.3651 - val_loss: 2.0525 - val_R2: 0.2677\n","Epoch 128/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7867 - R2: 0.3561 - val_loss: 2.2068 - val_R2: 0.2689\n","Epoch 129/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7303 - R2: 0.3947 - val_loss: 2.0734 - val_R2: 0.2775\n","Epoch 130/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7461 - R2: 0.3794 - val_loss: 2.1025 - val_R2: 0.2503\n","Epoch 131/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7665 - R2: 0.3748 - val_loss: 2.1710 - val_R2: 0.1779\n","Epoch 132/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7662 - R2: 0.3807 - val_loss: 2.1473 - val_R2: 0.2754\n","Epoch 133/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7537 - R2: 0.3807 - val_loss: 2.1119 - val_R2: 0.2895\n","Epoch 134/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8586 - R2: 0.3505 - val_loss: 2.2886 - val_R2: 0.1961\n","Epoch 135/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7827 - R2: 0.3638 - val_loss: 2.0934 - val_R2: 0.2923\n","Epoch 136/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.7795 - R2: 0.3609 - val_loss: 2.1660 - val_R2: 0.2714\n","Epoch 137/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7710 - R2: 0.3732 - val_loss: 2.0070 - val_R2: 0.3412\n","Epoch 138/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8099 - R2: 0.3550 - val_loss: 2.1720 - val_R2: 0.2732\n","Epoch 139/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7567 - R2: 0.3837 - val_loss: 2.6097 - val_R2: 0.0534\n","Epoch 140/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7443 - R2: 0.3910 - val_loss: 2.3927 - val_R2: 0.1079\n","Epoch 141/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.8008 - R2: 0.3654 - val_loss: 2.1544 - val_R2: 0.3102\n","Epoch 142/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7826 - R2: 0.3681 - val_loss: 2.1158 - val_R2: 0.2970\n","Epoch 143/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7701 - R2: 0.3717 - val_loss: 2.1842 - val_R2: 0.2779\n","Epoch 144/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7313 - R2: 0.3803 - val_loss: 2.0818 - val_R2: 0.3083\n","Epoch 145/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7921 - R2: 0.3595 - val_loss: 2.0517 - val_R2: 0.3099\n","Epoch 146/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.8112 - R2: 0.3624 - val_loss: 2.0837 - val_R2: 0.2859\n","Epoch 147/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7495 - R2: 0.3824 - val_loss: 2.0763 - val_R2: 0.3034\n","Epoch 148/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7696 - R2: 0.3710 - val_loss: 2.1308 - val_R2: 0.2800\n","Epoch 149/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7025 - R2: 0.4003 - val_loss: 2.1633 - val_R2: 0.2491\n","Epoch 150/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7805 - R2: 0.3632 - val_loss: 2.0999 - val_R2: 0.2638\n","Epoch 151/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7284 - R2: 0.3893 - val_loss: 2.0567 - val_R2: 0.3008\n","Epoch 152/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7758 - R2: 0.3687 - val_loss: 2.0809 - val_R2: 0.2903\n","Epoch 153/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7452 - R2: 0.3827 - val_loss: 2.1058 - val_R2: 0.2531\n","Epoch 154/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7632 - R2: 0.3782 - val_loss: 2.1230 - val_R2: 0.2815\n","Epoch 155/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7287 - R2: 0.3897 - val_loss: 2.1457 - val_R2: 0.2879\n","Epoch 156/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7289 - R2: 0.3907 - val_loss: 2.2057 - val_R2: 0.2649\n","Epoch 157/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7332 - R2: 0.3869 - val_loss: 2.0548 - val_R2: 0.3162\n","Epoch 158/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7399 - R2: 0.3680 - val_loss: 2.1970 - val_R2: 0.2782\n","Epoch 159/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7741 - R2: 0.3742 - val_loss: 2.1072 - val_R2: 0.2682\n","Epoch 160/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7209 - R2: 0.3846 - val_loss: 2.1952 - val_R2: 0.2280\n","Epoch 161/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7356 - R2: 0.3765 - val_loss: 2.1496 - val_R2: 0.2785\n","Epoch 162/2000\n","17/17 [==============================] - 0s 5ms/step - loss: 1.7265 - R2: 0.3877 - val_loss: 2.1885 - val_R2: 0.2376\n","Epoch 163/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7652 - R2: 0.3682 - val_loss: 2.1264 - val_R2: 0.2859\n","Epoch 164/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7220 - R2: 0.3848 - val_loss: 2.1229 - val_R2: 0.2972\n","Epoch 165/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7740 - R2: 0.3728 - val_loss: 2.1555 - val_R2: 0.2706\n","Epoch 166/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6962 - R2: 0.3965 - val_loss: 2.1227 - val_R2: 0.2770\n","Epoch 167/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7445 - R2: 0.3785 - val_loss: 2.0611 - val_R2: 0.3003\n","Epoch 168/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7127 - R2: 0.3968 - val_loss: 2.2592 - val_R2: 0.2095\n","Epoch 169/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7045 - R2: 0.3891 - val_loss: 2.0147 - val_R2: 0.3261\n","Epoch 170/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6937 - R2: 0.4050 - val_loss: 2.4307 - val_R2: 0.1313\n","Epoch 171/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7489 - R2: 0.3684 - val_loss: 2.2288 - val_R2: 0.2734\n","Epoch 172/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7150 - R2: 0.3889 - val_loss: 2.1500 - val_R2: 0.2557\n","Epoch 173/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6821 - R2: 0.4052 - val_loss: 2.0557 - val_R2: 0.2918\n","Epoch 174/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6587 - R2: 0.4081 - val_loss: 2.2592 - val_R2: 0.1742\n","Epoch 175/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7676 - R2: 0.3731 - val_loss: 2.0446 - val_R2: 0.3159\n","Epoch 176/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6951 - R2: 0.3852 - val_loss: 2.0833 - val_R2: 0.3202\n","Epoch 177/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6700 - R2: 0.4044 - val_loss: 2.1821 - val_R2: 0.2927\n","Epoch 178/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6727 - R2: 0.4165 - val_loss: 2.1396 - val_R2: 0.2677\n","Epoch 179/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6355 - R2: 0.4278 - val_loss: 2.3709 - val_R2: 0.2151\n","Epoch 180/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7008 - R2: 0.4014 - val_loss: 2.2597 - val_R2: 0.2476\n","Epoch 181/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6947 - R2: 0.4073 - val_loss: 2.1302 - val_R2: 0.2560\n","Epoch 182/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6868 - R2: 0.3909 - val_loss: 2.1503 - val_R2: 0.2686\n","Epoch 183/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7370 - R2: 0.3781 - val_loss: 2.2491 - val_R2: 0.2073\n","Epoch 184/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7584 - R2: 0.3741 - val_loss: 2.0747 - val_R2: 0.2953\n","Epoch 185/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6307 - R2: 0.4127 - val_loss: 2.1337 - val_R2: 0.2857\n","Epoch 186/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6739 - R2: 0.4044 - val_loss: 2.1534 - val_R2: 0.2700\n","Epoch 187/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7322 - R2: 0.3915 - val_loss: 2.0416 - val_R2: 0.3210\n","Epoch 188/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6641 - R2: 0.4111 - val_loss: 2.1741 - val_R2: 0.2726\n","Epoch 189/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.6717 - R2: 0.4121 - val_loss: 2.1347 - val_R2: 0.2686\n","Epoch 190/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7076 - R2: 0.3874 - val_loss: 2.1275 - val_R2: 0.2398\n","Epoch 191/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7279 - R2: 0.3911 - val_loss: 2.1702 - val_R2: 0.2638\n","Epoch 192/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7013 - R2: 0.3984 - val_loss: 2.0417 - val_R2: 0.3061\n","Epoch 193/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.6953 - R2: 0.3973 - val_loss: 2.0050 - val_R2: 0.3178\n","Epoch 194/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6632 - R2: 0.4051 - val_loss: 2.0495 - val_R2: 0.3042\n","Epoch 195/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7149 - R2: 0.3841 - val_loss: 2.1032 - val_R2: 0.2852\n","Epoch 196/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6949 - R2: 0.3996 - val_loss: 2.0780 - val_R2: 0.2866\n","Epoch 197/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6841 - R2: 0.4052 - val_loss: 2.0691 - val_R2: 0.2860\n","Epoch 198/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6632 - R2: 0.4108 - val_loss: 2.1290 - val_R2: 0.2698\n","Epoch 199/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6790 - R2: 0.3954 - val_loss: 2.0954 - val_R2: 0.2701\n","Epoch 200/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7247 - R2: 0.3969 - val_loss: 2.1204 - val_R2: 0.2697\n","Epoch 201/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6751 - R2: 0.4018 - val_loss: 2.1037 - val_R2: 0.3119\n","Epoch 202/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.7190 - R2: 0.3918 - val_loss: 2.0609 - val_R2: 0.3071\n","Epoch 203/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6868 - R2: 0.4058 - val_loss: 2.1505 - val_R2: 0.2962\n","Epoch 204/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6897 - R2: 0.4013 - val_loss: 2.7297 - val_R2: 0.0799\n","Epoch 205/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7489 - R2: 0.3792 - val_loss: 2.0487 - val_R2: 0.3255\n","Epoch 206/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6863 - R2: 0.4031 - val_loss: 2.0689 - val_R2: 0.2942\n","Epoch 207/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6588 - R2: 0.4166 - val_loss: 2.9895 - val_R2: -0.0136\n","Epoch 208/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7262 - R2: 0.3938 - val_loss: 2.5662 - val_R2: 0.1743\n","Epoch 209/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.7184 - R2: 0.3838 - val_loss: 2.1774 - val_R2: 0.2739\n","Epoch 210/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6987 - R2: 0.3983 - val_loss: 2.0429 - val_R2: 0.3158\n","Epoch 211/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6688 - R2: 0.4026 - val_loss: 2.0776 - val_R2: 0.3050\n","Epoch 212/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6894 - R2: 0.4083 - val_loss: 2.3644 - val_R2: 0.1712\n","Epoch 213/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6686 - R2: 0.4079 - val_loss: 2.0609 - val_R2: 0.2937\n","Epoch 214/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6753 - R2: 0.3955 - val_loss: 2.1867 - val_R2: 0.2850\n","Epoch 215/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6559 - R2: 0.4161 - val_loss: 2.1870 - val_R2: 0.2401\n","Epoch 216/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6867 - R2: 0.4048 - val_loss: 2.2777 - val_R2: 0.2321\n","Epoch 217/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6675 - R2: 0.4106 - val_loss: 2.1467 - val_R2: 0.2763\n","Epoch 218/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6637 - R2: 0.4062 - val_loss: 2.0637 - val_R2: 0.3020\n","Epoch 219/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.7096 - R2: 0.3924 - val_loss: 2.1572 - val_R2: 0.2550\n","Epoch 220/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6815 - R2: 0.4084 - val_loss: 2.0213 - val_R2: 0.3351\n","Epoch 221/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6701 - R2: 0.4097 - val_loss: 2.1029 - val_R2: 0.2978\n","Epoch 222/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6687 - R2: 0.4109 - val_loss: 2.0529 - val_R2: 0.3177\n","Epoch 223/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6523 - R2: 0.4079 - val_loss: 2.0773 - val_R2: 0.2600\n","Epoch 224/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6684 - R2: 0.4128 - val_loss: 2.0637 - val_R2: 0.2970\n","Epoch 225/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6426 - R2: 0.4166 - val_loss: 2.0980 - val_R2: 0.2969\n","Epoch 226/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6359 - R2: 0.4066 - val_loss: 2.1113 - val_R2: 0.3039\n","Epoch 227/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6459 - R2: 0.4166 - val_loss: 2.2229 - val_R2: 0.2123\n","Epoch 228/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.6868 - R2: 0.4018 - val_loss: 2.1079 - val_R2: 0.2581\n","Epoch 229/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6670 - R2: 0.4114 - val_loss: 2.1178 - val_R2: 0.2920\n","Epoch 230/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6344 - R2: 0.4222 - val_loss: 2.0514 - val_R2: 0.3274\n","Epoch 231/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6495 - R2: 0.4097 - val_loss: 2.1463 - val_R2: 0.2961\n","Epoch 232/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6574 - R2: 0.4153 - val_loss: 2.2587 - val_R2: 0.2143\n","Epoch 233/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6580 - R2: 0.4099 - val_loss: 2.1046 - val_R2: 0.2965\n","Epoch 234/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6783 - R2: 0.3908 - val_loss: 2.1024 - val_R2: 0.2999\n","Epoch 235/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6294 - R2: 0.4247 - val_loss: 2.1469 - val_R2: 0.2698\n","Epoch 236/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6234 - R2: 0.4177 - val_loss: 2.3296 - val_R2: 0.2296\n","Epoch 237/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6230 - R2: 0.4269 - val_loss: 2.0395 - val_R2: 0.3092\n","Epoch 238/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.6732 - R2: 0.4067 - val_loss: 2.0396 - val_R2: 0.3209\n","Epoch 239/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6296 - R2: 0.4195 - val_loss: 2.0856 - val_R2: 0.2846\n","Epoch 240/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6460 - R2: 0.4137 - val_loss: 2.1772 - val_R2: 0.2821\n","Epoch 241/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6805 - R2: 0.3941 - val_loss: 2.1223 - val_R2: 0.2948\n","Epoch 242/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6949 - R2: 0.3940 - val_loss: 2.1647 - val_R2: 0.2752\n","Epoch 243/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6718 - R2: 0.4087 - val_loss: 2.0585 - val_R2: 0.3228\n","Epoch 244/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6042 - R2: 0.4346 - val_loss: 2.1062 - val_R2: 0.3222\n","Epoch 245/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6930 - R2: 0.4040 - val_loss: 2.1117 - val_R2: 0.3047\n","Epoch 246/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6387 - R2: 0.4156 - val_loss: 2.1170 - val_R2: 0.2829\n","Epoch 247/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6551 - R2: 0.4065 - val_loss: 2.1513 - val_R2: 0.2815\n","Epoch 248/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6464 - R2: 0.4177 - val_loss: 2.1120 - val_R2: 0.3036\n","Epoch 249/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6642 - R2: 0.4060 - val_loss: 2.1677 - val_R2: 0.2471\n","Epoch 250/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6261 - R2: 0.4235 - val_loss: 2.1126 - val_R2: 0.2764\n","Epoch 251/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6249 - R2: 0.4296 - val_loss: 2.1097 - val_R2: 0.2845\n","Epoch 252/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6370 - R2: 0.4233 - val_loss: 2.1651 - val_R2: 0.2812\n","Epoch 253/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6499 - R2: 0.4174 - val_loss: 2.0760 - val_R2: 0.3128\n","Epoch 254/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6215 - R2: 0.4226 - val_loss: 2.3777 - val_R2: 0.2279\n","Epoch 255/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6659 - R2: 0.4136 - val_loss: 2.0658 - val_R2: 0.3251\n","Epoch 256/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6416 - R2: 0.4171 - val_loss: 2.1305 - val_R2: 0.3053\n","Epoch 257/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6138 - R2: 0.4199 - val_loss: 2.0218 - val_R2: 0.3217\n","Epoch 258/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.6180 - R2: 0.4273 - val_loss: 2.1207 - val_R2: 0.2912\n","Epoch 259/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6430 - R2: 0.4160 - val_loss: 2.0227 - val_R2: 0.3302\n","Epoch 260/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6122 - R2: 0.4385 - val_loss: 2.3416 - val_R2: 0.2039\n","Epoch 261/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6112 - R2: 0.4353 - val_loss: 2.1863 - val_R2: 0.2775\n","Epoch 262/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6829 - R2: 0.4054 - val_loss: 2.0068 - val_R2: 0.3310\n","Epoch 263/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6510 - R2: 0.4181 - val_loss: 2.2103 - val_R2: 0.2315\n","Epoch 264/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6008 - R2: 0.4195 - val_loss: 2.1807 - val_R2: 0.2869\n","Epoch 265/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6129 - R2: 0.4099 - val_loss: 2.0658 - val_R2: 0.3092\n","Epoch 266/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6433 - R2: 0.4238 - val_loss: 2.1025 - val_R2: 0.2886\n","Epoch 267/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.5909 - R2: 0.4389 - val_loss: 2.0936 - val_R2: 0.2787\n","Epoch 268/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6199 - R2: 0.4242 - val_loss: 2.1958 - val_R2: 0.2711\n","Epoch 269/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6327 - R2: 0.4234 - val_loss: 2.1363 - val_R2: 0.2735\n","Epoch 270/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6211 - R2: 0.4351 - val_loss: 2.2308 - val_R2: 0.2636\n","Epoch 271/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6694 - R2: 0.4133 - val_loss: 2.2945 - val_R2: 0.2378\n","Epoch 272/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6573 - R2: 0.4070 - val_loss: 2.0718 - val_R2: 0.3199\n","Epoch 273/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6570 - R2: 0.4109 - val_loss: 2.1108 - val_R2: 0.3047\n","Epoch 274/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6280 - R2: 0.4264 - val_loss: 2.1361 - val_R2: 0.2962\n","Epoch 275/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6522 - R2: 0.4130 - val_loss: 2.0794 - val_R2: 0.3193\n","Epoch 276/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.5951 - R2: 0.4436 - val_loss: 2.1016 - val_R2: 0.2919\n","Epoch 277/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6165 - R2: 0.4267 - val_loss: 2.1558 - val_R2: 0.2477\n","Epoch 278/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6433 - R2: 0.4160 - val_loss: 2.0784 - val_R2: 0.3075\n","Epoch 279/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6059 - R2: 0.4352 - val_loss: 2.4578 - val_R2: 0.1313\n","Epoch 280/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.6076 - R2: 0.4301 - val_loss: 2.0979 - val_R2: 0.3092\n","Epoch 281/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6248 - R2: 0.4331 - val_loss: 2.1028 - val_R2: 0.3043\n","Epoch 282/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.5671 - R2: 0.4521 - val_loss: 2.0723 - val_R2: 0.3165\n","Epoch 283/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6107 - R2: 0.4317 - val_loss: 2.1714 - val_R2: 0.2855\n","Epoch 284/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6303 - R2: 0.4206 - val_loss: 2.1864 - val_R2: 0.2541\n","Epoch 285/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6506 - R2: 0.4260 - val_loss: 2.1369 - val_R2: 0.3014\n","Epoch 286/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6187 - R2: 0.4202 - val_loss: 2.1261 - val_R2: 0.2770\n","Epoch 287/2000\n","17/17 [==============================] - 0s 8ms/step - loss: 1.6666 - R2: 0.4166 - val_loss: 2.1440 - val_R2: 0.2526\n","Epoch 288/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6115 - R2: 0.4332 - val_loss: 2.1776 - val_R2: 0.2829\n","Epoch 289/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6295 - R2: 0.4263 - val_loss: 2.2164 - val_R2: 0.2471\n","Epoch 290/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6156 - R2: 0.4191 - val_loss: 2.0231 - val_R2: 0.3359\n","Epoch 291/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.5774 - R2: 0.4439 - val_loss: 2.1783 - val_R2: 0.2980\n","Epoch 292/2000\n","17/17 [==============================] - 0s 6ms/step - loss: 1.6533 - R2: 0.4224 - val_loss: 2.2560 - val_R2: 0.2359\n","Epoch 293/2000\n","17/17 [==============================] - 0s 7ms/step - loss: 1.6256 - R2: 0.4275 - val_loss: 2.1573 - val_R2: 0.2689\n","Epoch 00293: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fbc843d6c50>"]},"metadata":{"tags":[]},"execution_count":229}]},{"cell_type":"code","metadata":{"id":"SyA7jfs4xDHq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwzZ8dWRnUSI","executionInfo":{"status":"ok","timestamp":1628692302137,"user_tz":180,"elapsed":219,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"6a9b48ae-b00b-45d5-e177-6f983b4f997c"},"source":["X.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PubchemFP0</th>\n","      <th>PubchemFP1</th>\n","      <th>PubchemFP2</th>\n","      <th>PubchemFP3</th>\n","      <th>PubchemFP4</th>\n","      <th>PubchemFP5</th>\n","      <th>PubchemFP6</th>\n","      <th>PubchemFP7</th>\n","      <th>PubchemFP8</th>\n","      <th>PubchemFP9</th>\n","      <th>PubchemFP10</th>\n","      <th>PubchemFP11</th>\n","      <th>PubchemFP12</th>\n","      <th>PubchemFP13</th>\n","      <th>PubchemFP14</th>\n","      <th>PubchemFP15</th>\n","      <th>PubchemFP16</th>\n","      <th>PubchemFP17</th>\n","      <th>PubchemFP18</th>\n","      <th>PubchemFP19</th>\n","      <th>PubchemFP20</th>\n","      <th>PubchemFP21</th>\n","      <th>PubchemFP22</th>\n","      <th>PubchemFP23</th>\n","      <th>PubchemFP24</th>\n","      <th>PubchemFP25</th>\n","      <th>PubchemFP26</th>\n","      <th>PubchemFP27</th>\n","      <th>PubchemFP28</th>\n","      <th>PubchemFP29</th>\n","      <th>PubchemFP30</th>\n","      <th>PubchemFP31</th>\n","      <th>PubchemFP32</th>\n","      <th>PubchemFP33</th>\n","      <th>PubchemFP34</th>\n","      <th>PubchemFP35</th>\n","      <th>PubchemFP36</th>\n","      <th>PubchemFP37</th>\n","      <th>PubchemFP38</th>\n","      <th>PubchemFP39</th>\n","      <th>...</th>\n","      <th>PubchemFP841</th>\n","      <th>PubchemFP842</th>\n","      <th>PubchemFP843</th>\n","      <th>PubchemFP844</th>\n","      <th>PubchemFP845</th>\n","      <th>PubchemFP846</th>\n","      <th>PubchemFP847</th>\n","      <th>PubchemFP848</th>\n","      <th>PubchemFP849</th>\n","      <th>PubchemFP850</th>\n","      <th>PubchemFP851</th>\n","      <th>PubchemFP852</th>\n","      <th>PubchemFP853</th>\n","      <th>PubchemFP854</th>\n","      <th>PubchemFP855</th>\n","      <th>PubchemFP856</th>\n","      <th>PubchemFP857</th>\n","      <th>PubchemFP858</th>\n","      <th>PubchemFP859</th>\n","      <th>PubchemFP860</th>\n","      <th>PubchemFP861</th>\n","      <th>PubchemFP862</th>\n","      <th>PubchemFP863</th>\n","      <th>PubchemFP864</th>\n","      <th>PubchemFP865</th>\n","      <th>PubchemFP866</th>\n","      <th>PubchemFP867</th>\n","      <th>PubchemFP868</th>\n","      <th>PubchemFP869</th>\n","      <th>PubchemFP870</th>\n","      <th>PubchemFP871</th>\n","      <th>PubchemFP872</th>\n","      <th>PubchemFP873</th>\n","      <th>PubchemFP874</th>\n","      <th>PubchemFP875</th>\n","      <th>PubchemFP876</th>\n","      <th>PubchemFP877</th>\n","      <th>PubchemFP878</th>\n","      <th>PubchemFP879</th>\n","      <th>PubchemFP880</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows  881 columns</p>\n","</div>"],"text/plain":["   PubchemFP0  PubchemFP1  PubchemFP2  ...  PubchemFP878  PubchemFP879  PubchemFP880\n","0           1           1           0  ...             0             0             0\n","1           1           1           0  ...             0             0             0\n","2           1           1           1  ...             0             0             0\n","3           1           1           1  ...             0             0             0\n","4           1           1           1  ...             0             0             0\n","\n","[5 rows x 881 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"LigfJr_8Z2Jc"},"source":["# Utilizando Embeddings"]},{"cell_type":"code","metadata":{"id":"VywgOaYgbIVa"},"source":["import os.path\n","\n","if not os.path.isfile('001_Data_retrieve.ipynb'):\n","    auth.authenticate_user()\n","    gauth = GoogleAuth()\n","    gauth.credentials = GoogleCredentials.get_application_default()\n","    drive = GoogleDrive(gauth)\n","    downloaded = drive.CreateFile({'id':'10fMCM9wnmjlyGwiyNzpfPROExiq8ukKk'})\n","    downloaded.GetContentFile('dataaug.py')\n","    downloaded = drive.CreateFile({'id':'1jPB1HDpGN5zFRuhqN6b9RLMuuUQy0UoB'})\n","    downloaded.GetContentFile('datagen.py')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oe5txybaasGd"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from datagen import smiles_dict, smiles_to_seq, DataGenerator\n","from dataaug import SmilesEnumerator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lpDIuBtcbjFr"},"source":["### Carga de Datos y seleccion de features y outputs"]},{"cell_type":"code","metadata":{"id":"d0Fe6HY3Z8Us"},"source":["df_completo = pd.read_csv(path+'data/acetylcholinesterase_02_bioactivity_data_preprocessed_token_descriptors.csv')\n","\n","max_len_idx = df_completo['canonical_smiles'].apply(len).argmax()\n","max_sequence_len = len(df_completo['canonical_smiles'].iloc[max_len_idx]) + 20\n","\n","X = df_completo['canonical_smiles'].values\n","y = df_completo['pIC50'].values\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ZJOYbwpfbWz"},"source":["###SPLIT DE DATOS y GENERATORS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfT66YwxfhY1","executionInfo":{"status":"ok","timestamp":1628771887468,"user_tz":180,"elapsed":627,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"9854ffab-bbab-43be-cff9-179863de2bba"},"source":["batch_size = 250\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","dgen_train = DataGenerator(X_train, y_train, seq_length=max_sequence_len, batch_size=batch_size, data_augmentation=True)\n","dgen_test = DataGenerator(X_test, y_test, seq_length=max_sequence_len, batch_size=batch_size, data_augmentation=False)\n","\n","for i, (X_b, y_b) in enumerate(dgen_train):\n","  print(X_b.shape, y_b.shape)\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4082, 227) (4082,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X1ffRrFMn9q5"},"source":["## TextCNN similar a la de deepchem"]},{"cell_type":"code","metadata":{"id":"d-xL4QnBmRti"},"source":["# Implementar modelo de TextCNN\n","def text_cnn_1d(sequence_length, vocab_size, embedding_size, filter_sizes, num_filters):\n","    # Recordar que estamos en la funcional model API y hay que entender que conectar con que.\n","    input_x = Input(shape=(sequence_length,), name='input_x')\n","                          # cant caracteres unicos, #long vect Emb,  #max vocabulario     \n","    embedding_layer = Embedding(vocab_size+1, embedding_size, input_length=sequence_length  )(input_x)\n","    pooled_outputs = []\n","    for filter_size in filter_sizes:\n","        conv1D = Conv1D( num_filters, filter_size, padding='valid')(embedding_layer) #sin activacion !!\n","        max_p = GlobalMaxPooling1D()(conv1D)\n","        pooled_outputs.append(max_p)\n","        \n","    h_pool = Concatenate(axis=1)(pooled_outputs)\n","    ##h_pool = Flatten()(h_pool)  #Flatten porque tengo MaxPool1D en vez de GlobalMaxPooling1D?\n","    h_pool = Dropout(0.1)(h_pool)\n","    dense = Dense(200, activation='relu')(h_pool)\n","    \n","    #dense = Dense(50, activation='relu')(dense)\n","    dense = Dense(1)(dense) # Salida\n","    model = Model(input_x, dense)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_H0TVM5LtWLp","executionInfo":{"status":"ok","timestamp":1628777573293,"user_tz":180,"elapsed":425,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"e3cd8ff5-961a-44ad-9ae3-f34a4dcfb96c"},"source":["len(smiles_dict)+1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"bNAur8vqsTDT"},"source":["\n","FILTER_SIZES = (3, 4, 5)\n","NUM_FILTERS = 128\n","vocab_size = len(smiles_dict)+1\n","embeddings_size = 128 # 2\n","learning_rate = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sWu0VczimRhs","executionInfo":{"status":"ok","timestamp":1628789826545,"user_tz":180,"elapsed":522,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"b0b8afad-7d38-465e-ac47-2942d102d208"},"source":["model = text_cnn_1d(max_sequence_len, vocab_size, embeddings_size, FILTER_SIZES, NUM_FILTERS)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_11\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_x (InputLayer)            [(None, 227)]        0                                            \n","__________________________________________________________________________________________________\n","embedding_18 (Embedding)        (None, 227, 128)     5632        input_x[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_13 (Conv1D)              (None, 225, 128)     49280       embedding_18[0][0]               \n","__________________________________________________________________________________________________\n","conv1d_14 (Conv1D)              (None, 224, 128)     65664       embedding_18[0][0]               \n","__________________________________________________________________________________________________\n","conv1d_15 (Conv1D)              (None, 223, 128)     82048       embedding_18[0][0]               \n","__________________________________________________________________________________________________\n","global_max_pooling1d_3 (GlobalM (None, 128)          0           conv1d_13[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_4 (GlobalM (None, 128)          0           conv1d_14[0][0]                  \n","__________________________________________________________________________________________________\n","global_max_pooling1d_5 (GlobalM (None, 128)          0           conv1d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 384)          0           global_max_pooling1d_3[0][0]     \n","                                                                 global_max_pooling1d_4[0][0]     \n","                                                                 global_max_pooling1d_5[0][0]     \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 384)          0           concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","dense_45 (Dense)                (None, 200)          77000       dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_46 (Dense)                (None, 1)            201         dense_45[0][0]                   \n","==================================================================================================\n","Total params: 279,825\n","Trainable params: 279,825\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RRvZBQEqt9OD","executionInfo":{"status":"error","timestamp":1628773338168,"user_tz":180,"elapsed":41445,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"68d661ae-bb9c-494e-a414-1234f2b9e75a"},"source":["model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=[R2])\n","history = model.fit(dgen_train, epochs=2000, validation_data=dgen_test, callbacks=[earlystop])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2000\n","17/17 [==============================] - 58s 1s/step - loss: 14.1173 - R2: -4.0675 - val_loss: 4.1901 - val_R2: -0.4516\n","Epoch 2/2000\n","17/17 [==============================] - 24s 1s/step - loss: 3.1212 - R2: -0.1204 - val_loss: 2.6510 - val_R2: 0.0816\n","Epoch 3/2000\n","17/17 [==============================] - 24s 1s/step - loss: 2.5712 - R2: 0.0770 - val_loss: 2.4168 - val_R2: 0.1627\n","Epoch 4/2000\n","17/17 [==============================] - 25s 1s/step - loss: 2.3397 - R2: 0.1601 - val_loss: 2.3064 - val_R2: 0.2010\n","Epoch 5/2000\n","17/17 [==============================] - 24s 1s/step - loss: 2.2574 - R2: 0.1897 - val_loss: 2.2235 - val_R2: 0.2297\n","Epoch 6/2000\n","17/17 [==============================] - 24s 1s/step - loss: 2.2029 - R2: 0.2093 - val_loss: 2.1679 - val_R2: 0.2489\n","Epoch 7/2000\n","17/17 [==============================] - 24s 1s/step - loss: 2.1501 - R2: 0.2282 - val_loss: 2.1169 - val_R2: 0.2666\n","Epoch 8/2000\n","17/17 [==============================] - 25s 1s/step - loss: 2.1008 - R2: 0.2459 - val_loss: 2.0641 - val_R2: 0.2849\n","Epoch 9/2000\n","17/17 [==============================] - 24s 1s/step - loss: 2.0392 - R2: 0.2680 - val_loss: 2.0022 - val_R2: 0.3063\n","Epoch 10/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.9640 - R2: 0.2950 - val_loss: 1.9453 - val_R2: 0.3261\n","Epoch 11/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.8901 - R2: 0.3215 - val_loss: 1.9009 - val_R2: 0.3414\n","Epoch 12/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.8291 - R2: 0.3434 - val_loss: 1.8424 - val_R2: 0.3617\n","Epoch 13/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.7700 - R2: 0.3646 - val_loss: 1.7861 - val_R2: 0.3812\n","Epoch 14/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.7194 - R2: 0.3828 - val_loss: 1.7434 - val_R2: 0.3960\n","Epoch 15/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.6610 - R2: 0.4038 - val_loss: 1.7044 - val_R2: 0.4095\n","Epoch 16/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.6231 - R2: 0.4174 - val_loss: 1.6597 - val_R2: 0.4250\n","Epoch 17/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.5691 - R2: 0.4367 - val_loss: 1.6307 - val_R2: 0.4350\n","Epoch 18/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.5309 - R2: 0.4505 - val_loss: 1.5909 - val_R2: 0.4488\n","Epoch 19/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.4783 - R2: 0.4693 - val_loss: 1.5596 - val_R2: 0.4597\n","Epoch 20/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.4348 - R2: 0.4850 - val_loss: 1.5334 - val_R2: 0.4688\n","Epoch 21/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.3935 - R2: 0.4998 - val_loss: 1.4910 - val_R2: 0.4835\n","Epoch 22/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.3516 - R2: 0.5148 - val_loss: 1.4618 - val_R2: 0.4936\n","Epoch 23/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.3194 - R2: 0.5264 - val_loss: 1.4389 - val_R2: 0.5015\n","Epoch 24/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.2845 - R2: 0.5389 - val_loss: 1.4029 - val_R2: 0.5140\n","Epoch 25/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.2563 - R2: 0.5490 - val_loss: 1.3752 - val_R2: 0.5236\n","Epoch 26/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.2300 - R2: 0.5585 - val_loss: 1.3543 - val_R2: 0.5308\n","Epoch 27/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.2013 - R2: 0.5688 - val_loss: 1.3334 - val_R2: 0.5381\n","Epoch 28/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.1850 - R2: 0.5746 - val_loss: 1.3243 - val_R2: 0.5412\n","Epoch 29/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.1646 - R2: 0.5819 - val_loss: 1.3296 - val_R2: 0.5394\n","Epoch 30/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.1385 - R2: 0.5913 - val_loss: 1.3022 - val_R2: 0.5489\n","Epoch 31/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.1219 - R2: 0.5973 - val_loss: 1.2890 - val_R2: 0.5534\n","Epoch 32/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.1061 - R2: 0.6029 - val_loss: 1.2826 - val_R2: 0.5557\n","Epoch 33/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.0876 - R2: 0.6096 - val_loss: 1.2871 - val_R2: 0.5541\n","Epoch 34/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.0820 - R2: 0.6116 - val_loss: 1.2752 - val_R2: 0.5582\n","Epoch 35/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.0649 - R2: 0.6178 - val_loss: 1.2532 - val_R2: 0.5658\n","Epoch 36/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.0538 - R2: 0.6217 - val_loss: 1.2621 - val_R2: 0.5627\n","Epoch 37/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.0306 - R2: 0.6300 - val_loss: 1.2786 - val_R2: 0.5570\n","Epoch 38/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.0172 - R2: 0.6349 - val_loss: 1.2459 - val_R2: 0.5684\n","Epoch 39/2000\n","17/17 [==============================] - 25s 1s/step - loss: 1.0183 - R2: 0.6345 - val_loss: 1.2415 - val_R2: 0.5699\n","Epoch 40/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9954 - R2: 0.6427 - val_loss: 1.2256 - val_R2: 0.5754\n","Epoch 41/2000\n","17/17 [==============================] - 24s 1s/step - loss: 1.0031 - R2: 0.6399 - val_loss: 1.2421 - val_R2: 0.5697\n","Epoch 42/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9752 - R2: 0.6499 - val_loss: 1.2252 - val_R2: 0.5755\n","Epoch 43/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9782 - R2: 0.6489 - val_loss: 1.1990 - val_R2: 0.5846\n","Epoch 44/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9665 - R2: 0.6531 - val_loss: 1.1993 - val_R2: 0.5845\n","Epoch 45/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9515 - R2: 0.6585 - val_loss: 1.2032 - val_R2: 0.5831\n","Epoch 46/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9420 - R2: 0.6619 - val_loss: 1.2434 - val_R2: 0.5692\n","Epoch 47/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9504 - R2: 0.6589 - val_loss: 1.3134 - val_R2: 0.5450\n","Epoch 48/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9385 - R2: 0.6631 - val_loss: 1.2492 - val_R2: 0.5672\n","Epoch 49/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9328 - R2: 0.6651 - val_loss: 1.2367 - val_R2: 0.5715\n","Epoch 50/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9208 - R2: 0.6695 - val_loss: 1.1874 - val_R2: 0.5886\n","Epoch 51/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9041 - R2: 0.6755 - val_loss: 1.1886 - val_R2: 0.5882\n","Epoch 52/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9053 - R2: 0.6750 - val_loss: 1.1607 - val_R2: 0.5979\n","Epoch 53/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.8932 - R2: 0.6794 - val_loss: 1.1779 - val_R2: 0.5919\n","Epoch 54/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.9183 - R2: 0.6704 - val_loss: 1.1602 - val_R2: 0.5980\n","Epoch 55/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.8922 - R2: 0.6798 - val_loss: 1.2274 - val_R2: 0.5748\n","Epoch 56/2000\n","17/17 [==============================] - 25s 1s/step - loss: 0.8809 - R2: 0.6838 - val_loss: 1.1711 - val_R2: 0.5943\n","Epoch 57/2000\n","11/17 [==================>...........] - ETA: 8s - loss: 0.8647 - R2: 0.6896"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ecf80a71ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgen_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdgen_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"nnLGc5TBuO4M"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0oC_l9WzWy5W"},"source":["# TSNE de Embeddings"]},{"cell_type":"code","metadata":{"id":"XzG2GiBC2nbr"},"source":["from sklearn.neighbors import NearestNeighbors\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.manifold import TSNE\n","import sklearn as sk\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3H9A4BrqCgLw"},"source":["## Embeddings "]},{"cell_type":"code","metadata":{"id":"O4zHNbg2250X"},"source":["##Parametros\n","k_vecinos = 5\n","n_pad = 0\n","reverse_smiles_dict = dict([(value, key) for (key, value) in smiles_dict.items()]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-p48XZRGdWyr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1TjZwTCxWxOi","executionInfo":{"status":"ok","timestamp":1628774945354,"user_tz":180,"elapsed":524,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"4359c73d-595b-4a6f-b481-89d3ff871879"},"source":["cargar_embeddings = False\n","grabar_embeddings = True\n","\n","if cargar_embeddings:\n","  embeddings = np.load(path+'data/embeddings_textcnn.npy')\n","else:\n","  #Obtengo los embeddings\n","  embeddings = model.layers[1].get_weights()[0] #obtengo los pesos de la primera capa, luego como es un lista de arrays, la paso a array haciendo list[0]\n","print('embeddings shape',embeddings.shape)\n","\n","#Si quiero grabar el embedding \n","if grabar_embeddings:\n","  np.save(path+'data/embeddings_textcnn', embeddings)\n","\n","#Obtener los 5 caracteres (atomos) mas cercanos segun distancia coseno\n","nearest = sk.neighbors.NearestNeighbors(k_vecinos, metric='cosine')\n","nearest.fit(embeddings)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["embeddings shape (44, 128)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n","                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n","                 radius=1.0)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"ADhI6ygE3jgb"},"source":["def get_nearest_words(nearest, embeddings, char, index, reverse_index, n_pad = 0):\n","  distances, nearest_indexes = nearest.kneighbors(embeddings[index[char]+n_pad].reshape(1,-1))  # Finds the K-neighbors of a point.\n","  lista_de_char = []\n","  for idx, d in zip(nearest_indexes[0], distances[0]):\n","    # Recordar restar el padding al reverse_index: reverse_index[idx-n_pad]\n","    lista_de_char.append(reverse_index[idx-n_pad])\n","  return lista_de_char\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VWf3d7vf5xBm","executionInfo":{"status":"ok","timestamp":1628774952018,"user_tz":180,"elapsed":3,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"236f5fec-412b-427f-9f83-7ffffcbeb33f"},"source":["print('5 moleculas mas similares a \"c\" con respecto a pIC50 son:' ,get_nearest_words(nearest, embeddings, 'c', smiles_dict, reverse_smiles_dict))\n","print('5 moleculas mas similares a \"#\" con respecto a pIC50 son:' ,get_nearest_words(nearest, embeddings, '#', smiles_dict, reverse_smiles_dict))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5 moleculas mas similares a \"c\" con respecto a pIC50 son: ['c', '4', 'n', '6', '1']\n","5 moleculas mas similares a \"#\" con respecto a pIC50 son: ['#', 'S', '4', 's', 'c']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kSqrAQ8YCzkQ"},"source":["## TSNE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F24lSP087Cey","executionInfo":{"status":"ok","timestamp":1628774958032,"user_tz":180,"elapsed":1583,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"56ea2d8c-41cb-4141-c369-e93f6b106c8e"},"source":["tsne = TSNE(2, verbose=1)\n","tsn_2d_emb = tsne.fit_transform(embeddings)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[t-SNE] Computing 43 nearest neighbors...\n","[t-SNE] Indexed 44 samples in 0.000s...\n","[t-SNE] Computed neighbors for 44 samples in 0.009s...\n","[t-SNE] Computed conditional probabilities for sample 44 / 44\n","[t-SNE] Mean sigma: 0.639239\n","[t-SNE] KL divergence after 250 iterations with early exaggeration: 59.584404\n","[t-SNE] KL divergence after 1000 iterations: 0.467138\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MNJK-80Ulh2x"},"source":["### INTERPRETACION DE TSNET (al menos lo trate :) )\n","Analizo si hay algunos chars caracteristicos bio_actividad alta o baja, ya que las predicciones que realiza el modelo son los pic50, una escala log. de standar_value, el cual se utiliza para clasificar como Activo --> standar_value >= 10000 e Inactivo Inactivos <1000 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KGKymg9HWEG","executionInfo":{"status":"ok","timestamp":1628775738269,"user_tz":180,"elapsed":340,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"68f74c71-16b8-4fb4-fae1-691d3b338dd2"},"source":["# Activos standar_value >= 10000   Inactivos <1000 y el 'pic50' es una escala log. del  standar_value -->df['standard_value'].apply(lambda x: -np.log10(x*(10**-9)))\n","df_active =  df_completo[df_completo.bioactivity_class=='active']\n","smiles_active_concat = df_active.canonical_smiles.str.cat()\n","\n","count_active = {}\n","for s in smiles_active_concat:\n","  if s in count_active:\n","    count_active[s] += 1\n","  else:\n","    count_active[s] = 1\n","\n","print('char mas activos:',{k: v for k, v in sorted(count_active.items(), key=lambda item: item[1], reverse=True)})\n","char_active = ['c', 'C', '(', ')', '1', 'O', '2', 'N','3', '=' ]\n","\n","\n","df_inactive =  df_completo[df_completo.bioactivity_class=='inactive']\n","smiles_inactive_concat = df_inactive.canonical_smiles.str.cat()\n","\n","count_inactive = {}\n","for s in smiles_inactive_concat:\n","  if s in count_inactive:\n","    count_inactive[s] += 1\n","  else:\n","    count_inactive[s] = 1\n","\n","print('char mas inactivos:',{k: v for k, v in sorted(count_inactive.items(), key=lambda item: item[1], reverse=True)})\n","char_active = ['c', 'C', '(', ')', '1', 'O', '2', 'N','3', '=' ]\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["char mas activos: {'c': 30335, 'C': 27390, '(': 9352, ')': 9352, '1': 6744, 'O': 5316, '2': 5250, 'N': 4415, '3': 3488, '=': 3395, '[': 2036, ']': 2036, 'n': 1840, '4': 1708, '@': 1294, 'H': 785, 'l': 740, '-': 720, '.': 601, '5': 588, '+': 504, 'o': 397, '/': 368, 'F': 340, 'S': 260, 'B': 258, 'r': 258, '6': 188, 's': 112, '#': 108, '\\\\': 70, 'I': 29, '7': 10, 'e': 10, 'P': 4, '8': 4, 'i': 2, 'a': 1}\n","char mas inactivos: {'c': 18177, 'C': 16437, '(': 6546, ')': 6546, '1': 4558, 'O': 4096, '2': 3506, 'N': 2551, '=': 2423, '[': 2253, ']': 2253, '@': 2060, '3': 1967, 'n': 1182, 'H': 1030, '4': 720, '/': 689, '-': 652, 'F': 443, '.': 420, '+': 407, 'l': 399, 'B': 227, 'r': 204, 'S': 165, 'o': 163, '\\\\': 161, '5': 138, '#': 107, 's': 38, 'I': 35, 'P': 17, 'e': 7, '6': 6, '7': 2}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-i1dth4LjeLB","executionInfo":{"status":"ok","timestamp":1628775740642,"user_tz":180,"elapsed":4,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"9b2361b1-29c5-432c-ad40-00c86fcd45a4"},"source":["set_activos = set(list(count_active.keys()))\n","set_inactivos = set(count_inactive.keys())\n","dist = set_activos.symmetric_difference(set_inactivos)\n","dist"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'8', 'a', 'i'}"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptzvgiNkDCad","executionInfo":{"status":"ok","timestamp":1628733642065,"user_tz":180,"elapsed":1001,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"2cb7a7f7-2b15-46c5-8479-d0526837bb6e"},"source":["plt.figure(figsize=(16,10))\n","plt.scatter(tsn_2d_emb[:,0], tsn_2d_emb[:,1], s=4)\n","for char in smiles_dict:\n","  plt.scatter(tsn_2d_emb[smiles_dict[char]+n_pad][0], tsn_2d_emb[smiles_dict[char]+n_pad][1], c='g', s=5, marker='D')\n","  plt.text(tsn_2d_emb[smiles_dict[char]+n_pad][0], tsn_2d_emb[smiles_dict[char]+n_pad][1], char, rotation='horizontal')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1152x720 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gboS2UvsDCQC","executionInfo":{"status":"ok","timestamp":1628777731856,"user_tz":180,"elapsed":507,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"103837a4-c81d-4de7-d478-a6922e772f51"},"source":["smiles_dict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'#': 1,\n"," '(': 2,\n"," ')': 3,\n"," '+': 43,\n"," '-': 5,\n"," '.': 35,\n"," '/': 6,\n"," '1': 7,\n"," '10': 41,\n"," '11': 42,\n"," '2': 8,\n"," '3': 9,\n"," '4': 10,\n"," '5': 11,\n"," '6': 12,\n"," '7': 13,\n"," '8': 14,\n"," '9': 40,\n"," '=': 15,\n"," '@': 34,\n"," 'B': 37,\n"," 'Br': 30,\n"," 'C': 16,\n"," 'Cl': 29,\n"," 'F': 17,\n"," 'H': 18,\n"," 'I': 19,\n"," 'N': 20,\n"," 'O': 21,\n"," 'P': 22,\n"," 'S': 23,\n"," '[': 24,\n"," '\\\\': 25,\n"," ']': 26,\n"," '_': 27,\n"," 'a': 36,\n"," 'c': 28,\n"," 'e': 38,\n"," 'i': 39,\n"," 'n': 31,\n"," 'o': 32,\n"," 's': 33}"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"_mcWcTclwq3W"},"source":["# ATTENTION"]},{"cell_type":"markdown","metadata":{"id":"F5POg1UfzChH"},"source":["## Cargar los Datos y Split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYZhrjW5y5XF","executionInfo":{"status":"ok","timestamp":1628781843210,"user_tz":180,"elapsed":1817,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"fbac0116-7150-4fa3-ca09-36dbabf710f8"},"source":["df_completo = pd.read_csv(path+'data/acetylcholinesterase_02_bioactivity_data_preprocessed_token_descriptors.csv')\n","\n","max_len_idx = df_completo['canonical_smiles'].apply(len).argmax()\n","max_sequence_len = len(df_completo['canonical_smiles'].iloc[max_len_idx]) + 20\n","\n","X = df_completo['canonical_smiles'].values\n","y = df_completo['pIC50'].values\n","\n","batch_size = 250\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","dgen_train = DataGenerator(X_train, y_train, seq_length=max_sequence_len, batch_size=batch_size, data_augmentation=True)\n","dgen_test = DataGenerator(X_test, y_test, seq_length=max_sequence_len, batch_size=batch_size, data_augmentation=False)\n","\n","for i, (X_b, y_b) in enumerate(dgen_train):\n","  print(X_b.shape, y_b.shape)\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4082, 227) (4082,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ucQEEQJE9cmi"},"source":["## MODELO: MLP + EMBEDDINGS + ATTENTION"]},{"cell_type":"code","metadata":{"id":"LyI0SgQjxXOF"},"source":["##Parametros\n","vocab_size = len(smiles_dict)+1\n","embeddings_size = 128 # 2\n","learning_rate = 0.01\n","embeddings_matrix = np.load(path+'data/embeddings_textcnn.npy')\n","key_dim=50\n","\n","\n","#nb_words=num_words\n","num_filters=64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdK2t-bgxB27","executionInfo":{"status":"ok","timestamp":1628782318257,"user_tz":180,"elapsed":337,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"1a689cbb-96ec-44b4-9679-9ee6a10678cf"},"source":["def softMaxOverTime(x):\n","    return softmax(x,axis=1)\n","\n","input_layer = Input(shape=(max_sequence_len,)) #input de dimension (None,500)\n","embedding_layer=Embedding(vocab_size+1, embeddings_matrix.shape[1], weights=[embeddings_matrix], input_length=max_sequence_len, trainable=False)(input_layer)\n","\n","#key_dim: Difine la long del vector de key o value, es cant de neurona de la densa, y tambien la cantidad de salida de ese capa.\n","dense_input=Dense(key_dim,activation=\"relu\")(embedding_layer) #SALIDA KEYS, es para reducir la dimension\n","ulog_attention=Dense(1,activation=\"linear\")(dense_input)#SALIDA SCORE, es de UNA neurona porque la Q que hago es si el compuesto es Activo o Inactivo !!! ???\n","attention=Activation(softMaxOverTime)(ulog_attention)#SALIDA ALFAS\n","\n","#Ahora tengo que multiplicar los alfas con cada Vector Embedding y luego sumarlo para obtener un vector de long 300\n","repeated_attention=TimeDistributed(RepeatVector(embeddings_matrix.shape[1]))(attention)\n","repeated_attention=Reshape([max_sequence_len,embeddings_matrix.shape[1]])(repeated_attention) # aplico reshape para None,500,300,1 --> None,500,300\n","weighted_embeddings=Multiply()([repeated_attention,embedding_layer]) #multiplico (ver imagen)\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)# sumo\n","\n","#tengo un embedding ponderador el cual le paso a la MLP como siempre\n","dense1=Dense(200, activation='relu')(embedding_sum)\n","dense1=Dense(50, activation='relu')(dense1)\n","dense2=Dense(1)(dense1)\n","\n","model=Model(input_layer , dense2)\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_11 (InputLayer)           [(None, 227)]        0                                            \n","__________________________________________________________________________________________________\n","embedding_9 (Embedding)         (None, 227, 128)     5632        input_11[0][0]                   \n","__________________________________________________________________________________________________\n","dense_26 (Dense)                (None, 227, 50)      6450        embedding_9[0][0]                \n","__________________________________________________________________________________________________\n","dense_27 (Dense)                (None, 227, 1)       51          dense_26[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 227, 1)       0           dense_27[0][0]                   \n","__________________________________________________________________________________________________\n","time_distributed_5 (TimeDistrib (None, 227, 128, 1)  0           activation_8[0][0]               \n","__________________________________________________________________________________________________\n","reshape_4 (Reshape)             (None, 227, 128)     0           time_distributed_5[0][0]         \n","__________________________________________________________________________________________________\n","multiply_4 (Multiply)           (None, 227, 128)     0           reshape_4[0][0]                  \n","                                                                 embedding_9[0][0]                \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 128)          0           multiply_4[0][0]                 \n","__________________________________________________________________________________________________\n","dense_28 (Dense)                (None, 200)          25800       lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","dense_29 (Dense)                (None, 50)           10050       dense_28[0][0]                   \n","__________________________________________________________________________________________________\n","dense_30 (Dense)                (None, 1)            51          dense_29[0][0]                   \n","==================================================================================================\n","Total params: 48,034\n","Trainable params: 42,402\n","Non-trainable params: 5,632\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THUWl7UUxBnu","executionInfo":{"status":"error","timestamp":1628783149249,"user_tz":180,"elapsed":813569,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"682997dd-7a21-4eb4-b8fa-ca53efe13c09"},"source":["model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=[R2])\n","history = model.fit(dgen_train, epochs=2000, validation_data=dgen_test, callbacks=[earlystop])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2000\n","17/17 [==============================] - 19s 1s/step - loss: 12.6991 - R2: -3.5584 - val_loss: 5.3979 - val_R2: -0.8701\n","Epoch 2/2000\n","17/17 [==============================] - 18s 1s/step - loss: 3.7960 - R2: -0.3626 - val_loss: 3.1426 - val_R2: -0.0887\n","Epoch 3/2000\n","17/17 [==============================] - 18s 1s/step - loss: 3.0239 - R2: -0.0854 - val_loss: 2.9790 - val_R2: -0.0321\n","Epoch 4/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.8620 - R2: -0.0273 - val_loss: 2.9538 - val_R2: -0.0233\n","Epoch 5/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.7581 - R2: 0.0099 - val_loss: 3.0046 - val_R2: -0.0409\n","Epoch 6/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.6880 - R2: 0.0351 - val_loss: 3.0511 - val_R2: -0.0570\n","Epoch 7/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.5963 - R2: 0.0681 - val_loss: 2.9847 - val_R2: -0.0340\n","Epoch 8/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.3886 - R2: 0.1426 - val_loss: 2.7777 - val_R2: 0.0377\n","Epoch 9/2000\n","17/17 [==============================] - 17s 1s/step - loss: 2.3186 - R2: 0.1677 - val_loss: 2.8059 - val_R2: 0.0279\n","Epoch 10/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.3012 - R2: 0.1740 - val_loss: 2.7924 - val_R2: 0.0326\n","Epoch 11/2000\n","17/17 [==============================] - 17s 1s/step - loss: 2.2863 - R2: 0.1793 - val_loss: 2.7678 - val_R2: 0.0411\n","Epoch 12/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.2637 - R2: 0.1874 - val_loss: 2.7393 - val_R2: 0.0510\n","Epoch 13/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.2357 - R2: 0.1975 - val_loss: 2.7314 - val_R2: 0.0537\n","Epoch 14/2000\n","17/17 [==============================] - 17s 1s/step - loss: 2.2092 - R2: 0.2070 - val_loss: 2.7055 - val_R2: 0.0627\n","Epoch 15/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.1641 - R2: 0.2232 - val_loss: 2.6680 - val_R2: 0.0757\n","Epoch 16/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.1037 - R2: 0.2449 - val_loss: 2.6345 - val_R2: 0.0873\n","Epoch 17/2000\n","17/17 [==============================] - 17s 1s/step - loss: 2.0540 - R2: 0.2627 - val_loss: 2.5954 - val_R2: 0.1008\n","Epoch 18/2000\n","17/17 [==============================] - 18s 1s/step - loss: 2.0106 - R2: 0.2783 - val_loss: 2.5378 - val_R2: 0.1208\n","Epoch 19/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.9895 - R2: 0.2859 - val_loss: 2.5027 - val_R2: 0.1330\n","Epoch 20/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.9656 - R2: 0.2944 - val_loss: 2.4877 - val_R2: 0.1381\n","Epoch 21/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.9419 - R2: 0.3029 - val_loss: 2.4680 - val_R2: 0.1450\n","Epoch 22/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.9197 - R2: 0.3109 - val_loss: 2.4865 - val_R2: 0.1386\n","Epoch 23/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.8964 - R2: 0.3193 - val_loss: 2.4568 - val_R2: 0.1489\n","Epoch 24/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.8756 - R2: 0.3267 - val_loss: 2.7061 - val_R2: 0.0625\n","Epoch 25/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.8953 - R2: 0.3196 - val_loss: 2.4625 - val_R2: 0.1469\n","Epoch 26/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.8324 - R2: 0.3422 - val_loss: 2.4395 - val_R2: 0.1548\n","Epoch 27/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.8127 - R2: 0.3493 - val_loss: 2.4391 - val_R2: 0.1550\n","Epoch 28/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.7971 - R2: 0.3549 - val_loss: 2.4494 - val_R2: 0.1514\n","Epoch 29/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.7809 - R2: 0.3607 - val_loss: 2.4520 - val_R2: 0.1505\n","Epoch 30/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.7631 - R2: 0.3671 - val_loss: 2.4234 - val_R2: 0.1604\n","Epoch 31/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.7484 - R2: 0.3724 - val_loss: 2.4210 - val_R2: 0.1613\n","Epoch 32/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.7341 - R2: 0.3775 - val_loss: 2.4110 - val_R2: 0.1647\n","Epoch 33/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.7236 - R2: 0.3813 - val_loss: 2.4025 - val_R2: 0.1677\n","Epoch 34/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.7138 - R2: 0.3848 - val_loss: 2.4095 - val_R2: 0.1653\n","Epoch 35/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.6955 - R2: 0.3914 - val_loss: 2.3617 - val_R2: 0.1818\n","Epoch 36/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.6849 - R2: 0.3952 - val_loss: 2.3509 - val_R2: 0.1855\n","Epoch 37/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.6750 - R2: 0.3987 - val_loss: 2.3530 - val_R2: 0.1848\n","Epoch 38/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.6605 - R2: 0.4040 - val_loss: 2.2996 - val_R2: 0.2033\n","Epoch 39/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.6585 - R2: 0.4047 - val_loss: 2.3255 - val_R2: 0.1944\n","Epoch 40/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.6443 - R2: 0.4098 - val_loss: 2.3126 - val_R2: 0.1988\n","Epoch 41/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.6276 - R2: 0.4158 - val_loss: 2.3033 - val_R2: 0.2020\n","Epoch 42/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.6218 - R2: 0.4178 - val_loss: 2.2639 - val_R2: 0.2157\n","Epoch 43/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.6233 - R2: 0.4173 - val_loss: 2.2563 - val_R2: 0.2183\n","Epoch 44/2000\n","17/17 [==============================] - 18s 1s/step - loss: 1.5934 - R2: 0.4280 - val_loss: 2.2345 - val_R2: 0.2259\n","Epoch 45/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.6024 - R2: 0.4248 - val_loss: 2.2288 - val_R2: 0.2279\n","Epoch 46/2000\n","17/17 [==============================] - 17s 1s/step - loss: 1.5909 - R2: 0.4289 - val_loss: 2.2939 - val_R2: 0.2053\n","Epoch 47/2000\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-ecf80a71ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgen_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdgen_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"F6FdLWrXAwRs"},"source":["## MODELO: MLP + EMBEDDINGS + ATTENTION + ContextCNN"]},{"cell_type":"code","metadata":{"id":"dbSMGFMJB-y4"},"source":["#parametros\n","\n","value_dim=100\n","learning_rate= 0.01\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcZJ3sIRBnkx","executionInfo":{"status":"ok","timestamp":1628792528922,"user_tz":180,"elapsed":363,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"58b6b0bc-d389-40d9-847d-64148dd479c0"},"source":["def softMaxOverTime(x):\n","    return softmax(x,axis=1)\n","\n","input_layer = Input(shape=(max_sequence_len,)) #input de dimension (None,500)\n","embedding_layer=Embedding(vocab_size+1, embeddings_matrix.shape[1], weights=[embeddings_matrix], input_length=max_sequence_len, trainable=False)(input_layer)\n","\n","\n","\n","conv_out=Conv1D(value_dim,10,padding=\"same\", activation='relu', name='CONV1')(embedding_layer)\n","    #conv_out=Activation(\"relu\")(conv_out)\n","#conv_out=Conv1D(embeddings_matrix.shape[1],3,activation=\"relu\",padding=\"same\")(conv_out)\n","conv_out=Conv1D(embeddings_matrix.shape[1],5,activation=\"tanh\",padding=\"same\", name='convTANH')(conv_out) #SALIDA KEYS\n","#FIN PARTE DISTINTA\n","\n","\n","ulog_attention=Dense(1,activation=\"linear\", name='DOT')(conv_out)#SALIDA SCORE, es de UNA neurona porque la Q que hago es si el compuesto es Activo o Inactivo !!! ???\n","attention=Activation(softMaxOverTime, name='SOFTMAX')(ulog_attention)#SALIDA ALFAS\n","\n","#Ahora tengo que multiplicar los alfas con cada Vector Embedding y luego sumarlo para obtener un vector de long 300\n","repeated_attention=TimeDistributed(RepeatVector(embeddings_matrix.shape[1]))(attention)\n","repeated_attention=Reshape([max_sequence_len,embeddings_matrix.shape[1]])(repeated_attention) # aplico reshape para None,500,300,1 --> None,500,300\n","weighted_embeddings=Multiply()([repeated_attention,embedding_layer]) #multiplico (ver imagen)\n","embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)# sumo\n","\n","#tengo un embedding ponderador el cual le paso a la MLP como siempre\n","dense1=Dense(200, activation='relu')(embedding_sum)\n","dense1=Dense(50, activation='relu')(dense1)\n","dense2=Dense(1)(dense1)\n","\n","model_attention_contectCNN=Model(input_layer , dense2)\n","\n","model_attention_contectCNN.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_31\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_49 (InputLayer)           [(None, 227)]        0                                            \n","__________________________________________________________________________________________________\n","embedding_48 (Embedding)        (None, 227, 128)     5632        input_49[0][0]                   \n","__________________________________________________________________________________________________\n","CONV1 (Conv1D)                  (None, 227, 100)     128100      embedding_48[0][0]               \n","__________________________________________________________________________________________________\n","convTANH (Conv1D)               (None, 227, 128)     64128       CONV1[0][0]                      \n","__________________________________________________________________________________________________\n","DOT (Dense)                     (None, 227, 1)       129         convTANH[0][0]                   \n","__________________________________________________________________________________________________\n","SOFTMAX (Activation)            (None, 227, 1)       0           DOT[0][0]                        \n","__________________________________________________________________________________________________\n","time_distributed_26 (TimeDistri (None, 227, 128, 1)  0           SOFTMAX[0][0]                    \n","__________________________________________________________________________________________________\n","reshape_20 (Reshape)            (None, 227, 128)     0           time_distributed_26[0][0]        \n","__________________________________________________________________________________________________\n","multiply_17 (Multiply)          (None, 227, 128)     0           reshape_20[0][0]                 \n","                                                                 embedding_48[0][0]               \n","__________________________________________________________________________________________________\n","lambda_16 (Lambda)              (None, 128)          0           multiply_17[0][0]                \n","__________________________________________________________________________________________________\n","dense_92 (Dense)                (None, 200)          25800       lambda_16[0][0]                  \n","__________________________________________________________________________________________________\n","dense_93 (Dense)                (None, 50)           10050       dense_92[0][0]                   \n","__________________________________________________________________________________________________\n","dense_94 (Dense)                (None, 1)            51          dense_93[0][0]                   \n","==================================================================================================\n","Total params: 233,890\n","Trainable params: 228,258\n","Non-trainable params: 5,632\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jHGQfheyCuQA","executionInfo":{"status":"error","timestamp":1628793148991,"user_tz":180,"elapsed":84852,"user":{"displayName":"Guillermo Burgener","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN2B4SPB6SK5w3Zx6CoFftwocB0c-oRN9ovneQag=s64","userId":"00323300485046539427"}},"outputId":"c1aedc9e-064a-4870-fb45-71650a79479f"},"source":["model_attention_contectCNN.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=[R2])\n","history = model_attention_contectCNN.fit(dgen_train, epochs=2000, validation_data=dgen_test, callbacks=[earlystop])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2000\n","17/17 [==============================] - 24s 1s/step - loss: 10.3323 - R2: -2.7089 - val_loss: 3.4662 - val_R2: -0.2008\n","Epoch 2/2000\n","17/17 [==============================] - 22s 1s/step - loss: 3.2419 - R2: -0.1637 - val_loss: 2.8883 - val_R2: -6.1893e-04\n","Epoch 3/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.8736 - R2: -0.0315 - val_loss: 2.9472 - val_R2: -0.0210\n","Epoch 4/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.8060 - R2: -0.0073 - val_loss: 2.8892 - val_R2: -9.4140e-04\n","Epoch 5/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7885 - R2: -9.6130e-04 - val_loss: 2.8879 - val_R2: -4.9841e-04\n","Epoch 6/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7864 - R2: -2.0123e-04 - val_loss: 2.8872 - val_R2: -2.3878e-04\n","Epoch 7/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7859 - R2: -3.7895e-05 - val_loss: 2.8865 - val_R2: -1.1921e-06\n","Epoch 8/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7859 - R2: -6.5425e-06 - val_loss: 2.8866 - val_R2: -4.7445e-05\n","Epoch 9/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -1.0974e-06 - val_loss: 2.8865 - val_R2: -1.7762e-05\n","Epoch 10/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -2.1388e-07 - val_loss: 2.8866 - val_R2: -2.7657e-05\n","Epoch 11/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -3.8568e-08 - val_loss: 2.8866 - val_R2: -2.6464e-05\n","Epoch 12/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 2.8049e-08 - val_loss: 2.8866 - val_R2: -2.5034e-05\n","Epoch 13/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -9.8172e-08 - val_loss: 2.8866 - val_R2: -2.5392e-05\n","Epoch 14/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -5.9605e-08 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 15/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 6.6617e-08 - val_loss: 2.8866 - val_R2: -2.5511e-05\n","Epoch 16/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -4.5580e-08 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 17/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 1.0518e-08 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 18/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 0.0000e+00 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 19/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 0.0000e+00 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 20/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 5.6098e-08 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 21/2000\n","17/17 [==============================] - 21s 1s/step - loss: 2.7858 - R2: 5.9605e-08 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 22/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -1.4025e-08 - val_loss: 2.8866 - val_R2: -2.5511e-05\n","Epoch 23/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 2.4543e-08 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 24/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 0.0000e+00 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 25/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: 0.0000e+00 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 26/2000\n","17/17 [==============================] - 21s 1s/step - loss: 2.7858 - R2: -3.5062e-08 - val_loss: 2.8866 - val_R2: -2.5511e-05\n","Epoch 27/2000\n","17/17 [==============================] - 21s 1s/step - loss: 2.7858 - R2: 0.0000e+00 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 28/2000\n","17/17 [==============================] - 22s 1s/step - loss: 2.7858 - R2: -3.1555e-08 - val_loss: 2.8866 - val_R2: -2.5630e-05\n","Epoch 29/2000\n"," 2/17 [==>...........................] - ETA: 19s - loss: 2.7858 - R2: 2.9802e-08"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-eb614d057baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_attention_contectCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_attention_contectCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgen_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdgen_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}